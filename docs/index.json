[{"categories":["Academy","Kubernetes"],"contents":"Our full Kubernetes Tutorial series Get up and running with your Kubernetes knowledge:\n What is Kubernetes? What is Kubernetes Monitoring? What is Kubernetes Management? What are Kubernetes secrets? What are Kubernetes pods? What is Kubernetes support? What is Enterprise Kubernetes?   A Kubernetes pod is a collection of one or more containers (such as Docker containers) that share network and storage resources and adhere to a set of operating rules. A pod\u0026rsquo;s contents are always co-located and co-scheduled and run in a shared context. Pods are the smallest deployable units in Kubernetes.\nPods include:\n  One or more containers, with shared storage/network resources.\n  A unique network IP address.\n  Optional information like labels (to be used with service discovery), secrets, volume mounts, and configuration data.\n  Pods abstract away low-level details like individual process IDs and hostnames (which are useful primarily for debugging). Pods also make it easy to deploy multiple replicas of an application. By tightly coupling containers in a pod, we can ensure that they have coordinated access to resources like disk space and memory, making it simpler to design self-healing systems. Finally, by sharing an IP address and port space, containers in a pod can easily find and communicate with each other using localhost.\nKubernetes pods provide an excellent way to increase the density of workloads on your servers while still maintaining strong isolation boundaries between individual applications. By packing multiple closely related apps into a single pod, you can take advantage of increased density without sacrificing isolation or performance.\nWhy Kubernetes Uses Pods Kubernetes uses pods to efficiently manage application deployments and scaling. By running multiple replicas of an application inside of pods, Kubernetes can ensure that the application is always available and can handle increased traffic without issue. When more capacity is needed, Kubernetes can simply create more pods to accommodate the increased demand. This makes it easy to scale an application up or down as needed.\nIn addition, managing individual pods instead of individual containers makes it easier to apply configuration changes and roll out updates. For example, if you need to update the configuration of an application, you can simply update the pod definition and redeploy it. This will ensure that all of the containers in the pod are updated with the new configuration.\nOverall, pods provide a convenient way to manage deployments and scaling while also allowing for easy updates and rollbacks. This makes them an ideal choice for running applications in Kubernetes.\nHow Do Kubernetes Pods Work? Pods are the smallest deployment unit in Kubernetes. An application container (or, in certain situations, many containers), storage resources, a specific network IP address, and configuration settings are all contained within a pod. Pods are always co-located and co-scheduled, meaning that they will be placed on the same node and that each pod will be scheduled to run on one or more nodes.\nPods enable data sharing and communication between containers within the same pod. Containers within the same pod can communicate with each other using localhost. Data is shared through volumes mounted into the containers. Network communication is handled by a shared network stack, which all containers in the pod use.\nPods also provide a way to specify how many instances of a given container should be running. This is known as a replication controller. The replication controller ensures that the specified number of pods are always running, even if individual pods crash or are deleted.\nDid you know, that you can get all this plus many more time-saving additions by using our EasyKube managed Kubernetes solution? Check it out now.\n\rManaging Pods With Kubectl Kubernetes is a powerful container orchestration tool that can help you manage and scale your applications. One of the features of Kubernetes is its ability to manage Pods, which are groups of any number of containers that share a network and storage space. You can use the kubectl tool to manage your Pods, and in this section, we\u0026rsquo;ll show you how.\nKubectl is a command-line tool that you can use to interact with your Kubernetes cluster. You can use it to create, update, and delete Pods, as well as to view their status and logs. In order to use kubectl, you\u0026rsquo;ll first need to install it on your workstation.\nYou can find installation instructions for various platforms here: https://kubernetes.io/docs/tasks/tools/install-kubectl/.\nOnce kubectl is installed, you can use it to manage your Pods. Let\u0026rsquo;s say you have a Pod with two containers, one for your application code and one for a database. To view the Pod\u0026rsquo;s details, you would run the following command:\nkubectl get pod my-pod This would return output similar to the following:\nNAME READY STATUS RESTARTS AGE my-pod 2/2 Running 0 1d To view the logs for the Pod, you would run the following command:\nkubectl logs my-pod -c my-container1 -c my-container2 --since=1h --tail=100 This would return the 100 most recent lines of logs from both containers in the Pod. If you just wanted to view the logs from one container, you could omit the -c my-container2 portion of the command.\nIf you need to update the code in one of your containers, you can use the kubectl set image command. For example, if you wanted to update the image for my-container1 to version 2.0, you would run the following command:\nkubectl set image pod my-pod my-container1=my-image:2.0 This would update the container\u0026rsquo;s image and restart it if necessary. If you wanted to update both containers in the Pod at once, you could omit the -c my-container2 portion of the command.\nFinally, if you need to delete a Pod, you can use the kubectl delete command. For example, if you wanted to delete my-pod, you would run the following command:\nkubectl delete pod my-pod This would delete the Pod and all its associated resources.\nKubectl is a powerful tool that can help you manage your Pods and keep them running smoothly. By learning how to use it properly, you\u0026rsquo;ll be able to take full advantage of all that Kubernetes has to offer.\nKubernetes Pods For Continuous Deployment Kubernetes Pods are a great way to continuously deploy your applications. By packaging your application into a Pod, you can ensure that it will always be up-to-date and available to your users. Pods also allow you to scale your application horizontally, by adding more Pods to your deployment. This is especially useful for applications that are heavy on resources, such as CPU or memory. By adding more Pods, you can ensure that your application can handle the load.\nFinally, Pods provide isolation for your application, which is important for security. By running your application in its own Pod, you can limit the exposure of your application to other parts of the system. This isolation also allows you to run multiple versions of your application side-by-side, which is useful for testing purposes. Kubernetes Pods are a powerful tool for Continuous Deployment, and they can help you keep your applications up-to-date and running smoothly.\nDid you know, that you can get all this plus many more time-saving additions by using our EasyKube managed Kubernetes solution? Check it out now.\n\rNext article: What is Kubernetes Support? Do I need a service package? Do I need to offer support myself for internal teams?\n","date":"11","image":null,"permalink":"/blog/what-are-kubernetes-pods/","tags":["Kubernetes","pods","Docker","K8s","Kubernetes pods","Tutorial"],"title":"What are Kubernetes pods?"},{"categories":["Academy","Kubernetes"],"contents":"Our full Kubernetes Tutorial series Get up and running with your Kubernetes knowledge:\n What is Kubernetes? What is Kubernetes Monitoring? What is Kubernetes Management? What are Kubernetes secrets? What are Kubernetes pods? What is Kubernetes support? What is Enterprise Kubernetes?   Kubernetes Secrets are a way of protecting data that is needed by applications running in a Kubernetes cluster, but which should not be exposed to the outside world. They are similar to Docker secrets and can be used to store sensitive information such as passwords, API keys, and SSL certificates. In this post, we will take a look at how Secrets work in Kubernetes, and we will see how they can be used to protect our data. We will also see how they can be created and managed using the Kubernetes command-line interface (CLI). Finally, we will take a look at some practical examples of how Secrets can be used in a Kubernetes environment.\nWhy Are Secrets Important? In the world of cloud computing, secret management is essential. Secrets are essentially pieces of information that should be kept hidden from unauthorized individuals. This can include everything from passwords and API keys to confidential files and sensitive data. In a Kubernetes cluster, secrets are used to store and manage sensitive information in a safe and secure manner.\nThere are a number of benefits to using secrets in Kubernetes, including improved security, enhanced compliance, and simplified management. Secrets can be easily created, updated, and deleted using the Kubernetes API-server.\nIn addition, secrets can be encrypted at rest using various encryption providers such as Vault by HashiCorp. By using Kubernetes secrets, businesses can protect their critical data and avoid the negative consequences of a data breach.\nHow Does Kubernetes Leverage Secrets? Secrets are stored as Base64-encoded data, and they can be used by pods to connect to external services or to perform other sensitive tasks. Secrets can be defined in a YAML file or created using the kubectl command-line tool. To use a secret, a pod must have permission to access the secret object. This can be accomplished by granting the appropriate RBAC roles to the service account that is used by the pod. Once a pod has been granted access to a secret, it can reference the secret data using environment variables.\nKubernetes also provides a way to inject secrets into containers using volumes. This approach is useful for cases where the application does not support referencing secrets via environment variables. When using volumes, the secret data is stored in a tmpfs volume, which is automatically mounted into the container when it is started. The tmpfs volume is only accessible by the container itself, providing an additional layer of security.\nSecrets can also be used to create TLS certificates that can be used to secure communications between pods. To generate a certificate, a Certificate Signing Request (CSR) must first be created. This CSR can then be submitted to a certificate authority (CA) to generate a signed certificate. The signed certificate and associated private key can then be stored as secrets in Kubernetes. These TLS secrets can be used by pods to establishing secure connections with each other.\nIn summary, secrets are an important part of managing sensitive information in Kubernetes. They can be used to store data such as passwords and API keys, as well as TLS certificates for securing communications between pods. Secrets are securely stored and can only be accessed by pods that have been granted permission to do so. This allows for fine-grained control over which pods have access to sensitive data.\nDid you know, that you can get all this plus many more time-saving additions by using our EasyKube managed Kubernetes solution? Check it out now.\n\rEditing A Secret You can edit a secret in Kubernetes by updating the YAML definition file for the secret and then applying the changes. To edit a secret, you first need to retrieve the current definition file for the secret. You can do this using the kubectl get command. For example, to retrieve the definition file for a secret named \u0026ldquo;my-secret\u0026rdquo;, you would use the following command:\nkubectl get secret my-secret -o yaml.\nThis will output the YAML definition file for the secret to stdout.\nOnce you have retrieved the current definition file for the secret, you can edit it using your preferred text editor. There are a few things to keep in mind when editing a Kubernetes secret definition file. First, each entry in the \u0026ldquo;data\u0026rdquo; map must be base64-encoded. Second, you must not change the size of any of the entries in the \u0026ldquo;data\u0026rdquo; map. If you need to add or remove an entry, you can do so by adding or removing a line from the \u0026ldquo;data\u0026rdquo; map. Finally, make sure to save your changes to the definition file before exiting your text editor.\nOnce you have made your changes to the definition file, you can apply them by using the kubectl apply command. For example, to apply my changes to the \u0026ldquo;my-secret\u0026rdquo; secret, I would use the following command:\nkubectl apply -f my-secret.yaml.\nThis will update the secret in Kubernetes with your new changes.\nBuilt-in Secret Types There are three types of secrets available in Kubernetes: generic, Opaque, and service account. Generic secrets can be used for storing any type of data, such as passwords, API keys, and certificates.\n  Opaque secrets are used for storing binary data, such as images. Service account secrets are used for authenticating Kubernetes APIs. Each type of secret has benefits and drawbacks that you should consider when deciding which type of secret to using.\n  Generic secrets are the most flexible type of secret, as they can be used for any type of data. However, they are also the least secure type of secret, as they are not encrypted by default. Opaque secrets are more secure than generic secrets, as they are encrypted by default. However, they cannot be used for storing non-binary data.\n  Service account secrets are the most secure type of secret, as they are both encrypted and signed by default. However, they can only be used for authenticating Kubernetes APIs.\n  When choosing a secret type, you should consider the security requirements of your application and the type of data you need to store. If security is your primary concern, then you should use a service account secret. If you need to store binary data, then you should use an opaque secret. If you need to store any other type of data, then you can use a generic secret.\nConclusion: Kubernetes Secrets provide a way to store and access sensitive information in a secure manner. They are important because they can help you keep your data safe, while still allowing you to use it when needed. Kubernetes leverages Secrets by using them to store passwords, API keys, and other sensitive information. Editing a Secret is easy, and there are several built-in Secret types that make it easy to securely store your data.\nDid you know, that you can get all this plus many more time-saving additions by using our EasyKube managed Kubernetes solution? Check it out now.\n\rNext article: What are Kubernetes pods, and why are they a central part of the whole system?\n","date":"11","image":null,"permalink":"/blog/what-are-kubernetes-secrets/","tags":["Kubernetes","Secrets","Security","K8s","Kubernetes Secrets","Tutorial"],"title":"What are Kubernetes secrets?"},{"categories":["Academy","Kubernetes"],"contents":"Our full Kubernetes Tutorial series Get up and running with your Kubernetes knowledge:\n What is Kubernetes? What is Kubernetes Monitoring? What is Kubernetes Management? What are Kubernetes secrets? What are Kubernetes pods? What is Kubernetes support? What is Enterprise Kubernetes?   In today\u0026rsquo;s business world, more and more companies are turning to the cloud to run their operations. Cloud-based applications and services offer a number of benefits, including scalability, flexibility, and cost savings. But not all clouds are created equal. In order to get the most out of the cloud, you need a platform that can provide the stability and performance your business needs. That\u0026rsquo;s where enterprise Kubernetes comes in. Keep reading to learn more about what enterprise Kubernetes is and how it can benefit your business.\nKubernetes Is Incomplete By Design As any DevOps engineer knows, Kubernetes is a powerful tool for managing containerized workloads. However, Kubernetes is also notoriously complex, and many users find it difficult to get started. This is by design - according to the principle of \u0026ldquo;minimum viable product\u0026rdquo;, Kubernetes is intentionally limited in scope in order to simplify the user experience. This approach has its benefits, but it also means that Kubernetes is not suitable for all use cases. In particular, users who need more advanced features or customization will be better off with a different tool. Nevertheless, for those who are willing to put in the effort, Kubernetes can be an extremely powerful way to manage containerized workloads.\nKubernetes Promotes Choice With Kubernetes, there are a lot of choices to be had in terms of what software to run, how to deploy it, and where to host it. This is a deliberate design decision - Kubernetes is meant to be a platform that can run anywhere, from on-premises datacenters to public clouds. As such, it needs to be flexible enough to accommodate different workloads and configurations.\nThis flexibility can be seen in the wide range of Kubernetes components that are available. For example, there are multiple container runtimes to choose from, including Docker, rkt, and CRI-O. There are also multiple storage solutions, networking plugins, and monitoring tools. This wealth of choice can be both a blessing and a curse - on one hand, it allows users to tailor their Kubernetes setup to their specific needs; on the other hand, it can be overwhelming for those who are just getting started with Kubernetes.\nIn any case, this flexibility is one of the key features of Kubernetes that sets it apart from other orchestration platforms.\nChoice Entails Risk Any time you have to make a choice, you\u0026rsquo;re also taking a risk. The same is true when choosing which container orchestration platform to use for your business. While Kubernetes has become the industry standard, it\u0026rsquo;s important to remember that it\u0026rsquo;s still a relatively new technology. That means that there are bound to be some quirks and bugs that need to be ironed out.\nIn addition, Kubernetes is a complex system, and it can be difficult to find qualified personnel who are able to effectively manage it. However, the benefits of Kubernetes often outweigh the risks. It\u0026rsquo;s a powerful platform that provides a lot of flexibility and scalability. In addition, the Kubernetes community is very active and always working on improving the platform. As a result, choosing Kubernetes is often a wise choice for businesses that need a robust container orchestration solution.\nKubernetes Components This section discusses the various enterprise Kubernetes components that are available to help you deploy and manage your containerized applications at scale.\nKubernetes Components - The various Kubernetes components that you would need to manage yourself include:\n  kube-apiserver: The kube-apiserver is the central component of the Kubernetes control plane and is responsible for exposing the Kubernetes API. It also acts as a proxy for all other Kubernetes API calls.\n  kube-controller-manager: The kube-controller-manager is responsible for managing the different types of controllers in Kubernetes such as replica sets, deployments, and service accounts.\n  kube-scheduler: The kube-scheduler is responsible for scheduling pods onto nodes in the Kubernetes cluster.\n  etcd: etcd is a key-value store used by Kubernetes to store materialized configuration data.\n  kubelet: The kubelet is the primary agent responsible for running pods on nodes in the Kubernetes cluster.\n  kube-proxy: The kube-proxy is a network proxy that runs on each node in the Kubernetes cluster and is responsible for forwarding traffic to the appropriate pod based on IP address and port number.\n  Container Network Interface (CNI): CNI is a library that defines APIs for writing network plugins to configure network interfaces in Linux containers. There are many CNI plugins available that can be used with Kubernetes such as Calico, Flannel, and Weave Net.\n  Cloud Controller Manager (CCM): The CCM is a cloud vendor-specific controller that runs in addition to the core controller components listed above. It provides integration with specific cloud provider APIs such as AWS, GCP, or Azure.\n  Helm: Helm is a package manager for installing and managing software packages in Kubernetes. It allows you to define, install, and upgrade your software packages using preconfigured templates called charts.\n  operator-sdk: The operator-sdk is a toolkit used for developing operators which are programs that extend Kubernetes to manage custom resources.\n  Sometimes it makes sense to let someone else worry about all parts working, and focus your time on the actual products. EasyKube is our managed Kubernetes solution - Check it out now.\n\rEnterprise Kubernetes And Software Development As software development teams have started to adopt containerization and orchestration using Kubernetes, they have realized significant benefits in speed and efficiency. However, many organizations are still struggling to get their Enterprise Kubernetes platforms up and running smoothly. In this article, we\u0026rsquo;ll take a look at some of the challenges involved in setting up an Enterprise Kubernetes platform, and how to overcome them.\nOne of the biggest challenges facing organizations is the lack of skilled resources. While there are many open-source resources available, it can be difficult to find personnel with the necessary skills to properly configure and manage a Kubernetes platform. Another challenge is the lack of integration between existing tools and processes. Many organizations\u0026rsquo; software development pipelines are not designed to work with Kubernetes, which can lead to increased complexity and reduced efficiency.\nFortunately, there are a number of ways to address these challenges. One option is to use a managed service such as Google Container Engine or Amazon EKS. These services provide pre-configured Kubernetes environments that can be easily integrated into existing development processes. Another option is to use a cloud-based IDE such as Cloud9, which gives developers access to a ready-to-use Kubernetes environment. Finally, there are a number of training resources available online that can help organizations get the most out of their Enterprise Kubernetes platforms.\nBy taking advantage of these options, organizations can overcome the challenges associated with setting up an Enterprise Kubernetes platform and reap the benefits of faster and more efficient software development.\nWhat Is Enterprise Kubernetes Then? Enterprise Kubernetes is an increasingly popular solution for large businesses that want to deploy and manage containerized applications at scale. While there are many options for deploying Kubernetes, enterprise Kubernetes platforms offer a number of unique benefits, including the ability to run multiple clusters in a single environment, support for multiple cloud providers, and advanced security features.\nUnlike some other Kubernetes distributions, enterprise Kubernetes platforms are designed to be easily deployed on-premises or in the cloud. As a result, they offer businesses a high degree of flexibility when it comes to deploying and managing containerized applications. In addition, enterprise Kubernetes platforms provide a number of tools and services that make it easy to monitor and manage clusters, making them an ideal solution for businesses that want to adopt Kubernetes at scale.\nDid you know, that you can get all this plus many more time-saving additions by using our EasyKube managed Kubernetes solution? Check it out now.\n\r","date":"11","image":null,"permalink":"/blog/what-is-enterprise-kubernetes/","tags":["Kubernetes","Enterprise","K8s","Enterprise Kubernetes","Tutorial"],"title":"What is Enterprise Kubernetes?"},{"categories":["Academy","Kubernetes"],"contents":"Our full Kubernetes Tutorial series Get up and running with your Kubernetes knowledge:\n What is Kubernetes? What is Kubernetes Monitoring? What is Kubernetes Management? What are Kubernetes secrets? What are Kubernetes pods? What is Kubernetes support? What is Enterprise Kubernetes?   When it comes to cloud-based computing, Kubernetes management is one of the hottest topics out there. Kubernetes has been called \u0026ldquo;the hottest thing in cloud computing\u0026rdquo; and for good reason – it\u0026rsquo;s a powerful tool that can help businesses manage their applications more effectively. But what is Kubernetes management and what can it do for your business? In this post, we\u0026rsquo;ll explore the basics of Kubernetes management and explain how it can benefit your organization. Stay tuned!\nWhy Use Kubernetes? If you\u0026rsquo;re looking for a way to improve the efficiency of your application development and deployment process, you may want to consider using Kubernetes. It is an open-source container orchestration tool that can assist you in automating the management of the containers used by your application. In addition, Kubernetes can provide you with the ability to scale your applications more easily and efficiently.\nHere are some of the benefits of using Kubernetes:\n  One of the most attractive features is its ability to automate tedious and time-consuming tasks related to deploying and managing applications. For example, Kubernetes can automatically scale your application up or down based on traffic levels, and it can also perform rolling updates to ensure that your application remains available during maintenance or upgrades. In addition, Kubernetes includes a rich set of tools for monitoring and logging, which can help you troubleshoot issues with your applications.\n  Another benefit of Kubernetes is its portability. It can be used with any type of container, including Docker containers. This makes it easy to migrate applications from one environment to another. For example, you could use Kubernetes to deploy your application on-premises, in the cloud, or even in a hybrid cloud environment.\n  Overall, Kubernetes provides a wealth of features and benefits that can be extremely helpful for businesses that are looking to modernize their IT infrastructure. If you\u0026rsquo;re considering using Kubernetes, be sure to take advantage of all that it has to offer.\n  How Does Kubernetes Work? Before we get too deep into the weeds of how Kubernetes works, let\u0026rsquo;s first provide some much-needed context. What exactly is Kubernetes? According to the official website \u0026ldquo;Kubernetes is an open platform for automating the deployment, scaling, and management of containerized applications.\u0026rdquo;\nNow that we have a basic understanding of what Kubernetes is, let\u0026rsquo;s take a closer look at how it works.\nFirst and foremost, Kubernetes is designed to run in a clustered environment. That means it relies on a group of servers (also known as nodes) to manage your application containers. Each node in a Kubernetes cluster runs a process called kubelet, which is responsible for orchestration.\nIn addition to kubelet, each node in a Kubernetes cluster also runs a container runtime (like Docker or rkt) and an agent called kube-proxy. Together, these components work to ensure that your applications are highly available and scalable.\nLast but not least, Kubernetes also includes a central control plane. The control plane is responsible for managing the state of the cluster. It does this by communicating with the kubelets on each node in the cluster.\nTo sum it up, Kubernetes is a powerful tool that can help you manage and deploy your application containers. It does this by running on a cluster of servers and using a central control plane to manage the state of the cluster. If you\u0026rsquo;re looking for an easy way to get started with container orchestration, Kubernetes is definitely worth checking out!\nHow Do You Manage Kubernetes Objects And Components? Kubernetes is a powerful container orchestration tool, but it can be daunting to manage all of the objects and components that make up a Kubernetes deployment. In this blog section, we\u0026rsquo;ll take a look at some of the best practices for managing Kubernetes objects and components.\nFirst, it\u0026rsquo;s important to understand the hierarchy of Kubernetes objects. At the highest level, there are namespaces, which are used to logically group resources. Within each namespace, there are deployments, which are groups of identical pods. Each pod contains one or more containers, which run the actual application code.\nNext, let\u0026rsquo;s take a look at some of the most important Kubernetes objects and components.\n The kube-apiserver is the central management component of Kubernetes. It provides a REST API for interacting with Kubernetes objects and components. The kube-controller-manager is responsible for controlling the lifecycle of Kubernetes objects, such as deployments and pods. The kube-scheduler determines where new pods should be placed within a deployment. And finally, the kubelet is responsible for actually running pods on nodes.  There are many other Kubernetes objects and components, but these are some of the most important ones to understand when starting out. By understanding how these objects and components work together, you\u0026rsquo;ll be well on your way to managing your own Kubernetes deployment.\nDid you know, that you can get all this plus many more time-saving additions by using our EasyKube managed Kubernetes solution? Check it out now.\n\rHow Do You Manage Kubernetes Clusters? Kubernetes clusters are a powerful way to manage containerized applications at scale. By grouping multiple containers together into a cluster, Kubernetes can provide enhanced availability and performance while reducing operational overhead.\nThere are a few key ways to manage Kubernetes clusters.\n  The first is through the use of labels. By applying labels to individual resources, operators can group and identify related objects. This can be helpful when managing large numbers of resources or when trying to track down a specific object.\n  The second way to manage Kubernetes clusters is through the use of annotations. Annotations provide a way to attach arbitrary metadata to resources. This metadata can be used for anything from providing descriptions to storing runtime configuration data.\n  Finally, operators can also manage Kubernetes clusters using custom resource definitions (CRDs). CRDs allows operators to extend the Kubernetes API with new types of resources. This can be used to add support for new types of objects or to modify the behavior of existing resource types.\n  By understanding these three ways to manage Kubernetes clusters, operators can more effectively apply container orchestration at scale.\nProduction Kubernetes Management Managing a production Kubernetes deployment is a complex and challenging task. There are a number of factors to consider, such as cluster size, node count, and pod count.\nIn addition, you must also account for network bandwidth, storage capacity, and CPU utilization. All of these factors must be carefully considered in order to ensure that your Kubernetes deployment is able to meet the demands of your applications.\nFurthermore, you must also be prepared to scale your deployment as your applications grow. Luckily, there are a number of tools available to help you manage your production Kubernetes deployment. The most popular tool is kubectl, which provides a powerful set of commands for managing your deployment.\nLastly, there are a number of third-party tools that can help you with specific tasks, such as provisioning new nodes or managing storage. With the right tools in place, you can be confident that your production Kubernetes deployment will run smoothly.\nDid you know, that you can get all this plus many more time-saving additions by using our EasyKube managed Kubernetes solution? Check it out now.\n\rNext article: What are Kubernetes Secrets, and how will they help me to keep sensitive data and password secure?\n","date":"11","image":null,"permalink":"/blog/what-is-kubernetes-management/","tags":["Kubernetes","Management","K8s","Kubernetes Management","Tutorial"],"title":"What is Kubernetes Management?"},{"categories":["Academy","Kubernetes"],"contents":"Our full Kubernetes Tutorial series Get up and running with your Kubernetes knowledge:\n What is Kubernetes? What is Kubernetes Monitoring? What is Kubernetes Management? What are Kubernetes secrets? What are Kubernetes pods? What is Kubernetes support? What is Enterprise Kubernetes?   Kubernetes is a fast-growing container orchestration platform that has gained a lot of traction in the last few years. Many companies are starting to use Kubernetes as their primary way of deploying applications and services. As Kubernetes usage increases, so does the demand for Kubernetes support. In this blog post, we will discuss what Kubernetes support is and why your company may need it. We will also provide some tips on how to find the right Kubernetes support provider for your business.\nWhy Do I need Kubernetes Support? Kubernetes is a powerful tool for managing containerized workloads and services, but it can be complex to set up and maintain. A Kubernetes support team can help you get the most out of your investment by providing expertise and guidance on best practices. Here are some of the ways a Kubernetes support team can be useful:\nDesign and set up an efficient Kubernetes cluster that meets your specific needs Kubernetes support is essential for anyone who wants to set up and maintain a Kubernetes cluster. Without support, it can be difficult to keep your cluster running smoothly and efficiently. A good support team will help you design and set up your cluster in a way that meets your specific needs. They can also provide ongoing support and maintenance so that you can focus on using Kubernetes to improve your business. In short, Kubernetes support is an essential part of using Kubernetes effectively. without it, you may find yourself struggling to get the most out of this powerful system.\nTrain your team members on how to use Kubernetes Kubernetes support training helps teams work more Kubernetically. This is a simple yet effective way to ensure that team members are able to use Kubernetes to its fullest potential. Kubernetes support training covers topics such as:\n Kubernetes Basics How to install and configure Kubernetes How to create and manage Kubernetes resources How to deploy applications on Kubernetes Kubernetes security best practices.  Kubernetes support training is an important part of any team\u0026rsquo;s arsenal, and it is recommended for all teams who want to make the most out of Kubernetes.\nStay up to date on the latest Kubernetes releases and features As anyone who has ever tried to keep up with the latest software releases knows, it can be a full-time job just to stay current. New features and updates are released at an ever-increasing pace, and it can be difficult to keep up. This is particularly true for those who are responsible for managing Kubernetes clusters. Not only is it important to stay up to date on the latest Kubernetes releases, but it is also important to have a good understanding of the new features and how they can be used. This is where Kubernetes support comes in.\nBy subscribing to a Kubernetes support plan, you can rest assured that you will always have access to the latest releases and features. In addition, you will have someone to help you if you run into any problems or have any questions. With Kubernetes support, you can focus on using Kubernetes instead of worrying about staying up to date.\nMonitor your Kubernetes cluster for performance and stability issues If you\u0026rsquo;re running a Kubernetes cluster, you need a way to monitor its performance and stability. That\u0026rsquo;s where Kubernetes support comes in. By using a tool like Datadog, you can get comprehensive visibility into your Kubernetes environment. With Datadog, you can collect and track metrics from all of your containers, pods, and nodes. You can also set up alerts to notify you of any potential issues.\nIn addition, Datadog provides built-in dashboards for popular Kubernetes metrics, making it easy to spot trends and identify problems. By using Datadog or another Kubernetes monitoring tool, you can ensure that your cluster is running smoothly and efficiently.\nAlternatives to Datadog are a self-built ELK stack (Elasticsearch, Logstash, Kubernetes), or a Prometheus plus Grafana distribution.\nHelp you troubleshoot problems when they arise No matter how well you engineer your system, problems will always arise. That\u0026rsquo;s why having Kubernetes support is so important. When something goes wrong, you need to be able to quickly identify and fix the problem. Otherwise, it can escalate and cause even more damage. With Kubernetes support, you have someone to help you troubleshoot the problem and get your system back up and running.\nIn addition, if you\u0026rsquo;re ever faced with a major outage, you\u0026rsquo;ll have someone on hand to help you recover. Without Kubernetes\u0026rsquo; support, you might be left scrambling to figure out what went wrong and that can be a costly mistake. So if you\u0026rsquo;re serious about keeping your system running smoothly, make sure you have Kubernetes support. It could be the difference between a minor hiccup and a major disaster.\nProvide guidance on using third-party tools and services with Kubernetes There are so many different components that need to be configured and kept track of, and any change can have unexpected consequences. Kubernetes is a tool that can help manage this complexity by providing a way to automate the deployment and management of containerized applications. While Kubernetes itself is fairly easy to use, it can be difficult to find good documentation on how to use it with third-party tools and services.\nThis is where Kubernetes support comes in. By providing guidance on the best practices for using Kubernetes, support teams can help organizations get the most out of this powerful tool. As a result, Kubernetes support can be incredibly valuable for any organization that is looking to adopt this technology.\nA Kubernetes support team can be a valuable resource for organizations of all sizes that are looking to get the most out of their investment in Kubernetes. By working with a support team, you can ensure that your Kubernetes cluster is set up correctly, runs smoothly, and is always up to date with the latest features.\nWhat are possible Kubernetes\u0026rsquo; Support Tiers? Kubernetes support tiers are a set of support levels designed to help users get the most out of their Kubernetes experience. If you are building up an internal team we recommend seperating support levels into three tiers: Standard, Premium, and Enterprise. Each tier offers different levels of support, features, and benefits.\n  The Standard tier is the most basic level of support. It includes access to community forums and online documentation. If you need help with Kubernetes, this is the best place to start.\n  The Premium tier adds 24/7 support from Kubernetes experts. You\u0026rsquo;ll also get access to exclusive video tutorials, training materials, and support tools. This tier is ideal for businesses that rely on Kubernetes for mission-critical applications.\n  The Enterprise tier is the highest level of support available. It includes all the features and benefits of the other two tiers, plus additional features designed for large businesses and enterprises. These include on-site support, account management, and priority access to new features and updates.\n  Who Supports Kubernetes? Can\u0026rsquo;t I Just Use The Kubernetes Community For Support? Any qualified enterprise should have some additional support for Kubernetes. It is an open-source system with many parts, including some optional ones. A company that wants to use Kubernetes needs to get it from a reliable provider who can also offer support. Red Hat and Canonical are examples of companies that offer enterprise-grade Kubernetes distributions that come with support. For example, with Red Hat OpenShift, customers get not only the software but also a subscription for access to the knowledge base and support from engineers. Likewise, with Canonical Distribution of Kubernetes, customers have access to phone and email support 24x7x365.\nSometimes organizations want to use a community distribution of Kubernetes but with enterprise-level support on top. In this case, we would recommend taking a look at Amazon Elastic Container Service for Kubernetes (EKS). EKS is designed for businesses or enterprises that want to run containers at scale but may not have the in-house expertise to operate their own Kubernetes clusters. With EKS, they can launch and manage production-ready Kubernetes clusters while AWS handles critical tasks like security patching, updates, and backup operations.\nEnterprise organisations need stability and predictability when it comes to container orchestration infrastructure so they can focus on developing and deploying applications rather than managing the underlying infrastructure. This is where having a supported version of Kubernetes comes in handy as it gives businesses the confidence that someone else is keeping an eye on things and has their back should anything go wrong.\nAre you stuck with something in Kubernetes? Or need a helping hand? Contact us for a free 15-minute consultation\n\rIs Kubernetes dropping Docker support? There has been some recent confusion about whether or not Kubernetes is dropping support for Docker. The short answer is that Kubernetes is not dropping support for Docker, and you can continue to use Docker with Kubernetes. However, there are some changes being made to the way that Kubernetes works with Docker, and you should be aware of these changes if you\u0026rsquo;re using Kubernetes in your development workflow.\nOne of the biggest changes is that Kubernetes is now using its own container runtime, called containerd. This change was made in order to improve support for multiple container runtimes, and to allow Kubernetes to better integrate with other tools and platforms. As a result of this change, you may see some differences in how your containers behave when running on Kubernetes. However, this change should not impact your ability to use Docker with Kubernetes.\nAnother change that\u0026rsquo;s being made is that the default storage driver for containers is being switched from devicemapper to overlay2. This change is being made in order to improve performance and reliability. Again, this change should not impact your ability to use Docker with Kubernetes.\nSo, in short, Kubernetes is not dropping support for Docker. However, there are some changes being made to how Kubernetes works with Docker, so you should be aware of these changes if you\u0026rsquo;re using Kubernetes in your development workflow.\nDid you know, that you can get all this plus many more time-saving additions by using our EasyKube managed Kubernetes solution? Check it out now.\n\rNext article: What is Enterprise Kubernetes, and what\u0026rsquo;s in store for me as a large organisation?\n","date":"11","image":null,"permalink":"/blog/what-is-kubernetes-support/","tags":["Kubernetes","support","HR","K8s","Kubernetes Support","Tutorial"],"title":"What is Kubernetes support? How do I provide internal support?"},{"categories":["Hosting","EasyHost"],"contents":"When it comes to creating an online shop or website, there are a few options available to you. The most popular systems are WordPress, Shopify, Magenta, or Shopware. In this blog post, we will compare Shopify and WordPress, as the main SAAS and Open-Source systems, with our in-house solution EasyHost. This will help you decide which is the best option for you.\nWordPress is a popular system that is used by millions of people around the world. It is a free system that is relatively easy to use. However, it does require some technical knowledge to set up your shop.\nShopify is a paid system that is also relatively easy to use. It offers more \u0026ldquo;plug and play\u0026rdquo;-features than WordPress, but it can be a little more expensive. EasyHost is our hosting solution, that uses static websites to reduce hosting cost, increase speed and make it nearly unhackable. This website is an EasyHost website!\nSAAS vs Self-hosted CMS or Shop systems SAAS describes the software, that is hosted by someone else, meaning you do not have to worry about much technical stuff. This is good if you just \u0026ldquo;want to get started\u0026rdquo;, but it also comes with a vendor lock-in. vendor-lock-in means, that it is harder to change your hosting provider, or integrate custom apps or plugins. Shopify is a SAAS system, and runs only on their servers, meaning you can not have a look at the source code, add things easily and change hosting providers. This means they can dictate the price of their service, and if a plugin or app becomes more expensive or unavailable in the future, you are left stranded.\nSelf-hosted, or open-source CMSs, are pieces of software that you need to install yourself. Even though this comes with a big hosting/tech effort, you will have almost complete control over what to run, including a full vision of the code itself.\nThe Pros and Cons of SAAS vs Self-hosted websites The good thing about SAAS, as stated above, is that you usually do not need to worry about many things. This comes with a price though. Shopify is starting at $29/month, but this is usually not even the final price. Every plugin and app costs extra, and if you want to include SEO tools, better order management, or nicer themes you will easily reach the $100-150/month range.\nThis can be quite much, especially if you are just starting with your business. If you are a startup with huge funds go for it, but in our opinion, the value-to-price ratio is not matching.\nAlso, the app and plugin range of Shopify is smaller than WordPress, and it is easier to \u0026ldquo;adapt\u0026rdquo; a plugin to fit your needs.\nIt is for example harder to integrate \u0026ldquo;custom\u0026rdquo; shop or website functionalities into Shopify compared to WordPress, like booking or price comparison pages.\nAn argument for self-hosted/WordPress is, therefore, that you will have complete control over everything. WordPress allows you to get started at around $5/month, and many plugins are free.\nBut what are the downsides of WordPress?\nWordPress tends to get slow if you are installing a lot of plugins, or if you have a lot of customers. WordPress is a dynamic website, meaning that each time you are visiting a WordPress website, the content needs to be calculated on the server, which slows it down a lot if a lot of people are visiting.\nAlso, WordPress is one of the main targets of hackers, as it is written in PHP, which is known for its many vulnerabilities. Additionally, it tends to break a lot, causing you downtime and the loss of a lot of visitors or customers. Even Google is factoring website speed into their results a lot.\nIntroducing the \u0026ldquo;static\u0026rdquo;-technology EasyHost is based on the \u0026ldquo;static\u0026rdquo; technology, which means that compared to WordPress, it renders the website on the device of the user, and pre-calculates a lot of things beforehand.\nImagine it like instructions to draw a picture. Whilst WordPress is starting to draw one picture for each visitor, depending on their device and settings, EasyHost pre-draws a lot of pictures and then just decides which to send to which visitor.\nThis saves a lot of resources, as the server does not nearly need to be as big as with self-hosted solutions.\nBut will I have the same nice UI as in WordPress or Shopify? Yes, as we are using the \u0026ldquo;forestry.io\u0026rdquo; CMS as an editing system. It is as easy as any CMS you have been using so far, and we are handling all the tech stuff in the background.\nSo which one is right for me - WordPress, Shopify, or EasyHost? This depends on your situation. EasyHost is situated in the middle between WordPress and Shopify, but for a cheaper price.\nIf you are a startup with a lot of funds, and you do not need many plugins, feel free to go with Shopify, as it lets you customize a lot of things and connections easily, without having a look at the code.\nIf you need a lot of customization, and you want full control, or hosting on your servers, you might want to go with WordPress.\nIf you want something in between have a look at EasyHost, or contact us for a free 15-minute consultation. EasyHost works for both websites and shops and offers a nice and easy-to-use CMS for non-tech users. If you decide to go with an EasyHost website, we will need to create or copy a website depending on your template choices one time, and after that, you will benefit from cheaper hosting than WordPress and Shopify. The best part: our one-time package starts from just $255, and continues with $10/month for hosting.\nAs the EasyHost website will be static, no hackers can hack it, and unless some breaking update is pushed, the website will not crash or experience downtimes, as it will be made available on at least three different servers located in Germany, Finland, and the US!\nThis will give you a nice international speed boost as well, leaving you with an almost 100 Google Pagespeed score.\nHead over to EasyHost, or contact us now to find out how we might be able to relieve you of your hosting stress!\n","date":"09","image":null,"permalink":"/blog/website-hosting-solutions-compared/","tags":["Hosting","Online shop","Shopify","WordPress","Websites"],"title":"Hosting solutions compared: Shopify vs WordPress vs EasyHost"},{"categories":["Academy","Kubernetes"],"contents":"Our full Kubernetes Tutorial series Get up and running with your Kubernetes knowledge:\n What is Kubernetes? What is Kubernetes Monitoring? What is Kubernetes Management? What are Kubernetes secrets? What are Kubernetes pods? What is Kubernetes support? What is Enterprise Kubernetes?   Kubernetes monitoring is the process of tracking the state of your Kubernetes deployment and identifying any issues that may arise. By monitoring your Kubernetes installation, you can ensure that your applications are running smoothly and efficiently. In this article, we\u0026rsquo;ll provide an overview of Kubernetes monitoring and discuss some of the best practices for keeping your Kubernetes environment healthy.\nWhy Kubernetes Monitoring Is Important If you\u0026rsquo;re running a containerized application, Kubernetes is probably orchestrating your deployment. Kubernetes makes it easy to deploy and manage containerized applications at scale. That\u0026rsquo;s one of the reasons why Kubernetes is so popular. But with great power comes great responsibility. As your application grows, so does the need for observability in the system. This is where Kubernetes monitoring comes in.\nKubernetes monitoring is important for a number of reasons.  First, it helps to ensure that the Kubernetes system is running smoothly and efficiently. By monitoring Kubernetes resources, administrators can identify bottlenecks and potential problems before they cause major disruptions. Second, Kubernetes monitoring can help to improve performance by providing visibility into how the system is being used. This information can be used to tune the system for better efficiency. Finally, Kubernetes monitoring helps to ensure security by providing visibility into who is accessing the system and what they are doing. This information can be used to detect and prevent unauthorized access or activity.  In summary, Kubernetes monitoring is important for a number of reasons including ensuring smooth operation, improving performance, and ensuring security.\nWhat Visibility Is Required For Kubernetes Monitoring? Kubernetes is a system for managing containerized applications across a cluster of nodes. To allow operators to monitor and troubleshoot applications, Kubernetes requires visibility into three layers of the system: the control plane, the data plane, and the application layer.\n  The control plane consists of the components that manage the state of the Kubernetes cluster, such as the API server, scheduler, and controller manager. To be able to monitor and troubleshoot the control plane, operators need visibility into the API server logs and metrics.\n  The data plane consists of the components that manipulate the data within the Kubernetes cluster, such as the kubelet and kube-proxy. To be able to monitor and troubleshoot the data plane, operators need visibility into the kubelet logs and metrics.\n  The application layer consists of the applications running within the Kubernetes cluster. To be able to monitor and troubleshoot applications, operators need visibility into application logs and metrics.\n  Did you know, that you can get all this plus many more time-saving additions by using our EasyKube managed Kubernetes solution? Check it out now.\n\rIn order to provide adequate visibility for monitoring and troubleshooting, operators must have access to all three layers of visibility. This can be accomplished by deploying a logging solution that collects data from all three layers and makes it available to operators in a central location.\nIn addition, operators should deploy a monitoring solution that provides visibility into all three layers in order to identify issues early and prevent them from becoming critical problems. By providing adequate visibility into all three layers of Kubernetes, operators can confidently monitor and manage their applications at scale.\nHow To Do Kubernetes Monitoring With the ever-growing popularity of containerized applications, Kubernetes has emerged as the leading container orchestration platform. But while Kubernetes can greatly simplify the deployment and management of containerized apps, it also introduces a new set of challenges when it comes to monitoring and logging. In this article, we\u0026rsquo;ll take a look at some of the best practices for Kubernetes monitoring.\nOne of the most important aspects of Kubernetes monitoring is tracking resource utilization. By understanding how your containers are using resources such as CPU and memory, you can ensure that your applications are running efficiently and avoid potential performance issues. The Kubernetes platform provides a number of tools for tracking resource utilization, including the kubelet stats API and the cadvisor metrics exporter. You can also use third-party tools such as Prometheus to collect and visualize resource usage data.\nAnother key aspect of Kubernetes monitoring is logging. Containerized applications often generate large volumes of log data, which can be difficult to manage and analyze. The ELK stack (Elasticsearch, Logstash, and Kibana) is a popular choice for collecting and visualizing log data, but there are a number of other options available as well. Once you have your logging solution in place, you\u0026rsquo;ll need to configure your containers to send their log output to the appropriate location. For example, you can use the fluentd DaemonSet to deploy a logging agent on every node in your Kubernetes cluster.\nMonitoring and logging are essential for any production-grade Kubernetes deployment. By following the tips in this article, you can make sure that your application is running smoothly and avoid potential problems down the road.\nDo you need help setting up a Kubernetes monitoring system? Contact us today! Our experts can help you choose the right tool for your needs and get your system up and running quickly.\nDid you know, that you can get all this plus many more time-saving additions by using our EasyKube managed Kubernetes solution? Check it out now.\n\rNext article: What is Kubernetes Management, and how does it help me manage my cluster better?\n","date":"09","image":null,"permalink":"/blog/what-is-kubernetes-monitoring/","tags":["Kubernetes","Monitoring","K8s","Kubernetes Monitoring","Tutorial"],"title":"What is Kubernetes Monitoring?"},{"categories":["Academy","Kubernetes"],"contents":"Our full Kubernetes Tutorial series Get up and running with your Kubernetes knowledge:\n What is Kubernetes? What is Kubernetes Monitoring? What is Kubernetes Management? What are Kubernetes secrets? What are Kubernetes pods? What is Kubernetes support? What is Enterprise Kubernetes?   Kubernetes is a system for managing containerized applications across a cluster of servers. It provides a number of features that make it well-suited for large-scale deployments, including:\n Horizontal scaling: Kubernetes can easily scale up or down, depending on the needs of the application. This makes it ideal for applications that experience sudden spikes in traffic. Self-healing: If a node in a Kubernetes cluster goes down, the system will automatically detect the failure and schedule the affected pods to be migrated to another node. This ensures that the application remains available even in the event of hardware failures. Service discovery and load balancing: Kubernetes can automatically discover and load balance services across the cluster. This simplifies the process of setting up new services and reduces the overall complexity of the deployment.  Kubernetes is rapidly becoming the standard tool for managing large-scale deployments of containerized applications. Thanks to its robust feature set and ease of use, it is well suited for a wide variety of workloads.\nHow Does Kubernetes Work? In a nutshell, Kubernetes is a tool for managing containerized applications at scale. It provides a way to automate the deployment, scaling, and management of applications running in containers. Kubernetes is often used in conjunction with Docker, an open-source container runtime.\nKubernetes is made up of a number of components, each of which plays a key role in its operation. The most important components are:\n The Master Node: The Master node is responsible for managing the Kubernetes cluster. It contains the cluster state and all of the control plane components. The Worker Nodes: Worker nodes are where your applications actually run. They are managed by the Master node and receive tasks from it. etcd: etcd is a key-value store that is used to store the Kubernetes cluster state. The Scheduler: The Scheduler is responsible for assigning pods to nodes. It takes into account factors such as resource utilization and node capacity when making decisions. The Controller Manager: The Controller Manager is a process that runs various controllers responsible for managing the state of the cluster. Examples of controllers include the Replication Controller, which ensures that the desired number of replicas of a pod is always running, and the Endpoints Controller, which populates the Endpoints object with information about pods that should receive traffic from a Service.  Why Use Kubernetes? Kubernetes is a powerful container orchestration tool that can help you manage and deploy your applications more efficiently. Some of the benefits of using Kubernetes include:\n Increased efficiency: With Kubernetes, you can automate the deployment and management of your applications, which can save you time and increase your productivity. Greater flexibility: Kubernetes allows you to run your applications on any infrastructure, whether it\u0026rsquo;s on-premises or in the cloud. Improved uptime: Kubernetes can help you achieve higher uptime for your applications by providing features such as self-healing and automatic rollbacks. reduced costs: By using Kubernetes, you can reduce the costs associated with managing and deploying your applications.  As you can see, there are many benefits to using Kubernetes. If you\u0026rsquo;re looking for a tool to help you manage your applications more effectively, Kubernetes is a great option to consider.\nWhere Can I Run Kubernetes? Kubernetes can be run on a variety of platforms, including public clouds, private clouds, and on-premises servers. Public cloud providers such as Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) all offer managed Kubernetes services. These providers take care of the underlying infrastructure and provide additional features such as autoscaling and monitoring. Private cloud platforms such as OpenStack and VMware vSphere can also be used to run Kubernetes.\nAnd finally, Kubernetes can also be installed on Bare metal servers or virtual machines running Linux or Windows. In most cases, it is best to use a managed Kubernetes service from a public cloud provider, but the flexibility to run Kubernetes anywhere can be useful in certain circumstances.\nDid you know, that you can get all this plus many more time-saving additions by using our EasyKube managed Kubernetes solution? Check it out now.\n\rWhat Is A Kubernetes Cluster? A Kubernetes cluster is a set of virtual machines (nodes) that run containerized applications. Kubernetes automates the installation, growth, and administration of containerized applications. For simple management and discovery, it divides the containers that make up an application into logical parts.\nA Kubernetes cluster can be deployed on a cloud platform or on-premises. Each node in a Kubernetes cluster runs a process called kubelet, which manages the containers on that node. The nodes communicate with each other through a shared storage Volume.\nA Kubernetes cluster also has a scheduler that assigns pods to nodes and a controller manager that tracks the state of the cluster and makes sure that the desired state is maintained.\nIn addition, there is an API server that exposes the API and allows users to interact with the cluster. A Kubernetes cluster can be used to manage both stateless and stateful applications. Stateless applications are those where the data is not stored on the nodes, such as web servers. Stateful applications are those where the data is stored on the nodes, such as database servers. Kubernetes clusters can also be used to manage hybrid applications that have both stateless and stateful components.\nOur fully managed Kubernetes saves you a lot of time setting up volumes, networking and more, starting at $12.99/month, all hosted in Germany! Visit EasyKube\n\rWhat Is \u0026ldquo;Enterprise Kubernetes\u0026rdquo;? When you hear the term \u0026ldquo;Kubernetes,\u0026rdquo; you might think of it as something related to container virtualization or perhaps as an open-source system for automating the deployment, scaling, and management of containerized applications. However, \u0026ldquo;enterprise Kubernetes\u0026rdquo; is a term that is now being used to describe a new class of software that helps organizations manage their Kubernetes deployments at scale.\nEnterprise Kubernetes platform providers offer a variety of features that can make it easier for organizations to deploy and manage Kubernetes clusters, including support for multiple cluster types (e.g., development, staging, production), integration with existing IT infrastructure (e.g., monitoring, logging, identity management), and tools for simplifying cluster administration. In addition, many enterprise Kubernetes platforms include features that are designed to make it easier for organizations to migrate their applications from traditional server-based environments to containers.\nWhile there are a number of different enterprise Kubernetes platform providers to choose from, some of the more popular options include Red Hat OpenShift, VMware Pivotal Container Service (PKS), and Canonical Charmed Kubernetes. Each platform has its own unique set of features and pricing models, so it\u0026rsquo;s important to evaluate your organization\u0026rsquo;s specific needs before selecting a platform.\nWhen used correctly, enterprise Kubernetes can be a powerful tool for managing large-scale container deployments. By taking advantage of the features offered by enterprise Kubernetes platforms, organizations can reduce the complexity of their deployments and gain greater control over their containerized environments.\nHow Do I Start Using Kubernetes? Before you can start using Kubernetes, you need to meet a few conditions. Your Linux distribution must be running the kernel version that Kubernetes requires and support the features that Kubernetes needs. In addition, you\u0026rsquo;ll need to have a user account with sudo privileges as well as a text editor installed on your system. With that said, let\u0026rsquo;s take a look at the steps involved in setting up Kubernetes.\nKubernetes is comprised of a number of components, each of which can be installed separately. However, the easiest way to get started is to use a pre-packaged solution such as Minikube. Minikube is a single-node Kubernetes cluster that can be run on your local machine. To install Minikube, simply follow the instructions for your particular platform.\nOnce Minikube is up and running, you can start using Kubernetes. The first thing you\u0026rsquo;ll need to do is create a deployment. A deployment is a group of identical pods that are used to expose an application or service. To create a deployment, you\u0026rsquo;ll use the kubectl create command. This command will take care of creating the necessary pods as well as setting up networking and storage for your application.\nNow that your deployment is created, you can access your application by creating a service. A service is an abstraction that defines a set of pods and exposes them to clients. You can create a service by using the kubectl expose command. This command will take care of creating the necessary load balancer and routing rules for your service.\nWith that, you\u0026rsquo;re now ready to start using Kubernetes!\nNext Article: What is Kubernetes Monitoring, and how will it help me reduce downtime and spot errors?\nAre you interested in a fully managed Kubernetes? Our fully managed Kubernetes saves you a lot of time setting up volumes, networking and more, starting at $12.99/month, all hosted in Germany! Visit EasyKube\n\r","date":"09","image":null,"permalink":"/blog/what-is-kubernetes/","tags":["Kubernetes","How does Kubernetes Work?","K8s","Master Node","Worker Node"],"title":"What is Kubernetes?"},{"categories":["EasyKube"],"contents":"Kubernetes can be complex, but once you get to know the basics, it is a wonderful tool allowing you to get up and running quickly. Once you have deployed your first services, there are common pitfalls in terms of security that you might miss. This article touches on the Top 7 misconceptions.\nGrab your free PDF Download of this article, including a free Checklist!!\n\r1. Kubernetes Namespaces isolate containers Thinking that namespaces isolate containers is a common misconception. They are only showing up in that specific namespace, but are not isolated from each other. Let us say you are running a postgresql deployment in the \u0026ldquo;default\u0026rdquo; namespace as service name \u0026ldquo;psql-deployment\u0026rdquo;. If you start up another container, you are able to connect to it connecting to \u0026ldquo;psql-deployment:5432\u0026rdquo;. Now, if you move your second deployment to another namespace, you will not be able to connect anymore.\nNow it might be easy to think that namespaces isolate network resources, but the truth is only the routing changed, and the pod can still communicate with the psql-deployment. We could try this out by using the internal DNS routing called \u0026ldquo;psql-deployment.default.svc.cluster.local\u0026rdquo;. As you can see the structure is [SERVICE].[NAMESPACE].svc.cluster.local, and every service can be accessed with that.\nThis poses a huge security risk but can be avoided by using special networking plugins in Kubernetes. Common plugins are Calico, Flannel, Weave, and Cilium. They can be set up to isolate namespaces, and containers, and specify different Security Groups and Access Control Lists as you might know from other cloud providers.\n2. Inter-Node communication in Kubernetes is encrypted A similar issue happens with the communication between Kubernetes nodes. Let us say you are encrypting your WordPress (or any other) traffic with automated Cert-Manager and Letsencrypt. All good, right? Wrong - because traffic in between nodes is unencrypted by default. But what does that mean?\nIf one node is located in Frankfurt, and another in Munich for availability reasons (good on you!), the communication between nodes still happens unencrypted. This means, that anyone gaining access to the data center connection could read your traffic!\nOf course, this is quite strongly prevented if your hosting provider is reliable, but especially if you are using self-hosted setups you should be careful in doing this. And what can you do against that? You could either manually use self-signed certificates for the pods, or - easier - use Kubernetes plugins for that. The previously mentioned networking plugins offer a lot of functionality. The plugins implement a so-called \u0026ldquo;service mash\u0026rdquo;, which deploys a sidecar along with your pod, that is taking care of TLS termination with mTLS enabled between pods.\nCalico does not implement this by default, but Linkerd and Istio can use traffic encryption in combination with Calico. Linkerd is the easiest plugin in these regards, as it implements mTLS out of the box.\n3. Velero Backups are secured and encrypted Say you have Backups implemented, and save them to AWS S3 for safekeeping. A good step for sure in terms of disaster recovery, but did you know, that Velero does not encrypt your backups by default? This can have serious implications if you are running an isolated self-hosted Kubernetes cluster because you are from the finance industry or store medical data, but the backup is stored in true form on an American cloud provider.\nMany European countries specify to not use American cloud providers due to security risks involved, and many still keep on using S3 for backups. If someone accesses these object storages in the public cloud, there is no encryption on the files stored.\nUnfortunately, at the time of writing, there is no Backup service offering encryption. My solution was to create custom Kubernetes Jobs, that dump the data, encrypt it in the Job, and then store it in object storage provider interfaces.\n4. Kubernetes secrets are encrypted You might have created secrets in Kubernetes, and might have taken a look at them in your running cluster. \u0026ldquo;aWxvdmV0ZW5kaWVz\u0026rdquo;, wow that looks quite encrypted! But again the hard truth is: Wrong! Kubernetes saves Secrets and a lot of other variables as base64 encoded strings. Base64 is just an encoding, and no encryption, meaning we can easily, without any keys, \u0026ldquo;translate\u0026rdquo; the above string into the true form. Try it out yourself with tools like e.g. https://www.base64encode.org/! This means, that if someone gets access to your Kubernetes cluster, he can just read all your secrets. This is currently not completely preventable, but good solutions exist.\nFor example \u0026ldquo;Sealed Secrets\u0026rdquo;, allow you to encrypt your secrets at rest and in transit on creation. The decryption key is stored in the cluster itself, which is where the secrets get decrypted. This still means though, that if the cluster itself gets compromised, the encryption key is compromised, but at least during creation and when storing the secrets on Github, they remain safe.\nA slightly more complex approach by Bitnami, the \u0026ldquo;Helm secrets\u0026rdquo;, can use a Key Management system like AWS KMS or Google CKM to encrypt and decrypt secrets. That way, you do not have to share the same encryption key with all your developers, but only specific developers have access to the encryption keys of their applications, even in the cluster.\nStill, the secrets remain \u0026ldquo;pure\u0026rdquo; in the cluster itself, which is another reason to pay close attention to not losing your Admin Kubeconfig.\n5. Using the same user for everything This brings us to our next point. When creating new clusters your provider usually gives you one Kubeconfig file. This is the admin file, and you can do anything with it. Even though it is tempting, you should never use it except for creating other users and permissions. That way, if one user and role for a specific app or namespace gets compromised, it has no control over the others. The solution is called RBAC (role based access control).\nNumber 6 is only available in our free PDF Download of this article!!\n\r7. Ignoring resource limits I know, it is tempting to just write your deployments and publish them. But you should at least set namespace limits, or even better deployment resource limits, as this prevents you from a lot of headaches further down the road.\nKubernetes managed resources automatically, which is amazing, but if someone attacks one specific service of yours with a DDOS attack (basically a lot of traffic), the resources for that deployment will consume almost all Kubernetes resources and all the other applications will fail.\nThis can be troublesome if your organization uses one huge cluster without these limits. It does not even have to be an attack. It can be an application with bugs, that enters an infinite loop or just eats all the resources. The solution is to define deployment - or at least - namespace limits. That way, if a namespace reaches that hard limit, the application will be contained, and the other applications keep on running.\nI hope this list gave you a nice picture of what you can do to improve security in your Kubernetes deployment. What was new to you? Did I miss something? Let me know in the comments, and feel free to reach out to me to discuss your Kubernetes projects. Did you know that I am offering a worry-free managed Kubernetes called \u0026ldquo;EasyKube? Go and have a look!\u0026rdquo;\n","date":"14","image":null,"permalink":"/blog/post-1/","tags":["Kubernetes","Security","K8s","Backups","Encryption"],"title":"Top 7 Kubernetes Security Misconceptions and Myths"},{"categories":null,"contents":"","date":"01","image":null,"permalink":"/about/","tags":null,"title":"About Us"},{"categories":null,"contents":"Use a newer browser to see this video.   -- Consultation and Programming Having a broad knowledge of Cloud, Data and DevOp technologies, we will be able to consult and help you with any project\n Python, Go, Web \u0026amp; React programmers ETL pipelines SQL \u0026amp; NoSQL experts Kubernetes Docker Cloud Strategies and Business Decisions  EasyServices is a product of DataFortress.cloud UG  Portfolio Hourly Rates  Book a free 15-minute consultation to get an individual offer.\n  Free 15-minute consultation  ","date":"01","image":null,"permalink":"/services/consulting/","tags":null,"title":"Consulting \u0026 Development"},{"categories":null,"contents":"","date":"01","image":null,"permalink":"/contact/","tags":null,"title":"Contact Us"},{"categories":null,"contents":"Use a newer browser to see this video.   -- Managed Databases You just want your databases to run, not caring about scaling, availability or downtime?\nEasyDB is your solution\n  Free 15-minute consultation on EasyDB   Why a managed database? Hosting your own databases can be tricky, especially for the following situations:\n What happens if the database version is old and it gets hacked? What happens if I accidentally delete my database? Is there a backup? What happens if the datacenter is offline? What will my customers say if they can not log in? How much revenue will I loose if I do not have access to my data? What happens if my website gets bigger and the database can\u0026rsquo;t handle the load?  As you can see, it would be way easier to just use a database service, and let someone else worry about it. This is why we created EasyDB.\nData privacy issues in the public cloud If you are from the financial or health industry, or in general from an industry using sensitive data, you can not have a data breach situation without destroying your business and loosing a lot of customers.\nEasyDB is fully hosted in Germany, and therefore compliant with German and EU based law.\nAnd on top of that EasyDB is giving you:\n Automatic database updates Database backups SSL communication (LetsEncrypt certificate) Autoscaling Backup of your data in three availability zones Distribution to two data centers if wished, to increase uptime Optional hosting in the US and Finland Postgresql (relational database / SQL database) MongoDB (non-relational / NoSQL database)    Free Demo to see EasyDB in action!   EasyDB Pricing overview Pricing for both MongoDB and Postgresql\n   Feature EasyDB XS EasyDB S EasyDB M EasyDB L EasyDB XL Custom     Hosting in Germany ✅ ✅ ✅ ✅ ✅ ✅   SSL/HTTPS (letsencrypt) ✅ ✅ ✅ ✅ ✅ ✅   4 TB traffic / m ✅ ✅ ✅ ✅ ✅ ✅   Free subdomain of easycloudhost.de ✅ ✅ ✅ ✅ ✅ ✅   Multi AZ ❌ ❌ ✅ ✅ ✅ ✅   Custom Domain ❌ ❌ ✅ ✅ ✅ ✅   Dedicated Machines ❌ ❌ ❌ ✅ ✅ ✅   Velero Backups ❌ ❌ ❌ ✅ ✅ ✅   Horizontal Autoscaling ❌ ❌ ❌ ❌ ❌ ✅   Support extra extra 2h/month 5h/month ✅ ✅   Volumes included [2] 10 GB 20 GB 100 GB 500 GB ✅ ✅   Uptime guarantee ❌ 80% 95% 99% 99.9% ✅   Nr nodes 1 1 3 3 5 10   vCPU total 1 3 9 15 30 300   RAM GB total 1 3 9 20 40 400   Monthly payment 12.99€/m 29.99€/m 99.99€/m 199.99€/m 4,999€/m Contact us   Comparable price [4] 73$/m + nodes = 103$/m 153$/m 243$/m 893$/m 21.000$/m custom    We can offer Backups and everything for smaller packages as well, choose \u0026ldquo;custom\u0026rdquo; to get an individual offer\nPrices are automatically converted to your local currency on checkout\n 9€/m | 19€/m | 55.75€/m | 104.20€/m | 2,100€/m | Contact us | -- [2] 10 GB Minimum, 10 TB Maximum per single volume\n\r[4] https://calculator.aws/#/addService/EKS\n\r  Free Demo to see EasyDB in action!  ","date":"01","image":null,"permalink":"/services/easydb/","tags":null,"title":"EasyDB"},{"categories":null,"contents":" Use a newer browser to see this video.  Next Video: Tech-Demo\n Did you know, that over 60% of development time is spent on DevOp tasks instead of working on the actual product [1]?\n\rWhat if there could be a way to \u0026ldquo;just run code\u0026rdquo; instead of worrying about servers and clusters?\nEasyFAAS (Easy-Function-as-a-service) lets you run your code in an easy environment, without hidden costs.\n  Get Started for free!   Why should I choose EasyFAAS over other providers? Whilst we were working with FAAS services of other providers, we usually ended up having problems with two specific things:\n (EU) Data Security Complexness  1. Our problems with (EU) Data Security Even though FAAS services of other cloud providers are technically secure, they still have the problem of being hosted by an american company. This can be a problem for EU-based companies, as the american \u0026ldquo;patriot act\u0026rdquo; states, that the US government can basically request your data from american companies to \u0026ldquo;intercept and obstruct terrorism\u0026rdquo;. There have been unconfirmed reports of misuse as well, where industry and intellectual secrets were requested.\nThis proves to be especially dangerours for companies in the finance industry, or in general where companies have an intellectual competitive advantage.\n\rOf course no one can surely say (yet) that this is really happening, and that it is not only used for the defeat of terrorism, but our company and many others agree that your data should only belong to you.\n2. Our problems with complexness Now back to a happier topic: The FAAS services of other cloud providers are amazing. They are versatile, well integrated in their system, and were a technological novelty. Our problem has just been, that if you want to \u0026ldquo;just get going\u0026rdquo;, meaning just pasting your code, you will often experience that it is not that easy.\nThe technical interconnections with other services come with a price: You will find yourself setting up API Gateways if you want the service to connect to the outside, where you will need to know about ports, firewalls, security groups and even networking.\nAlso, if you are using custom packages like Python\u0026rsquo;s numpy and pandas, you will have to create an extra layer, which proves to be quite complex, instead of just listing the packages that are used.\nOne of our main applications in the past has been to create little APIs that write and read from a database. In other FAAS solutions, this requires you to create the networking, the database connection and the custom layer to get started, which involved a lot of repetitive tasks.\nIn our EasyFAAS solution this becomes as simple as this:\nContents  Overview Serverless Function Types Managed MongoDB Getting started  EasyFAAS Main Dashboard Creating a new function Code Example: Bitcoin price getter The function Detail page   Billing  Introduction EasyFAAS reduces time to market, and let\u0026rsquo;s your programmers focus on what it important: your code!\nDid you know that you can run one function per month for free? Claim your free function\n\rTo achieve this EasyFAAS currently supports two functions:\n1. Serverless functions  Distinguished into \u0026ldquo;simple\u0026rdquo; and \u0026ldquo;storage\u0026rdquo; functions Distinguished into \u0026ldquo;timed\u0026rdquo; and \u0026ldquo;continuous\u0026rdquo; functions  2. A managed MongoDB NoSQL database  Easy integration without much setup into your EasyFAAS functions  1. Serverless functions overview A \u0026ldquo;storage\u0026rdquo; function distinguishes itself from a \u0026ldquo;simple\u0026rdquo; function, in that it offers persistence, meaning that if a function crashes, or restarts, that objects saved in the path \u0026quot;/mnt/persistent/\u0026quot; will be saved.\nA \u0026ldquo;timed\u0026rdquo; function distinguishes itself from the \u0026ldquo;continuous\u0026rdquo; function, in that the timed one is running at a specific schedule, whilst the continuous is running constantly.\nThese two settings can be combined, resulting in a total of four combinable possibilities for serverless functions:\n1.1 Simple-Continuous function  Good for web applications that do not require storage. Examples:  you want an API or website displayed where data does not have to be stored you want to download current crypto prices and calculate the exchange rate between two pairs    1.2. Simple-Timed function  Good for jobs that you want to have executed, that do not require storage Examples:  triggering other endpoints with post requests starting external backups downloading data and writing it into the managed MongoDB    1.3. Storage-Continuous function  Good for web applications that require storage. Examples:  An API that receives current users as json and saves them to disk An API or website that needs to save pictures to disk    1.4. Storage-Timed function  Good for jobs that require storage Examples:  You want to download price data every hour and save it into a CSV file You want to create backups of a database    2. Managed MongoDB overview In case storage on disk is not enough, you can easily spin up a managed mongodb instance, which you can easily access from your serverless functions.\nA managed MongoDB makes sense, if you want to run multiple functions that are all accessing the same information, like if you distributed your workloads into several functions, or you are running functions in parallel.\nThe big benefits of the managed MongoDB service are, that contrary to other hosting providers it will remain in a custom network, meaning it is not exposed to the internet, but you can still easily access it in your functions.\nThis means you do not have to worry about SSL connections, strong passwords or other things, and can easily get it up and running in seconds. An example to connect with python is as follows:\nfrom pymongo import MongoClient client = MongoClient(\u0026#39;mongodb://mongodb:27017/\u0026#39;) This saves you from a lot of steps compared to other hosting providers, where you need to set up SSL certificates, ports, firewalls and user password combinations.\nExample applications for the managed MongoDB are:\n You are saving items as json into MongoDB using custom EasyFAAS functions. If one function is not enough, you can simply scale your function up, and the load will be distributed to two functions automatically. You are building an ETL pipeline, where the first function collects data and saves it into the database, the second applies calculations to it and writes it again into the database, and the third one serves the result as an API  1. Getting started EasyFAAS currently only supports Python, but we have Node, React and others already implemented. Tell us about your code preferences and we might be able to get it working.\n\r1.1 The main dashboard Head over to https://shop.easycloudhost.de/contact/ and register or login.\n  The main dashboard is the central control system for EasyFAAS. In here, you will se an overview over the different services that are available.\n1.2 Create a new function Next click on New function, which takes you to the function type selection screen.\nWhat is a timed, and what is a continuous function?\n\rA timed function is best suited for jobs that do not need to run all the time, but rather run at specific intervals. If you have used Cron in the past, this is pretty much it. You can define Cron schedules as you are used to, like for example    Cron expression   Meaning    30 2 * * * Every day at 2:30   30 * * * * Every day, every hour at :30 (2:30, 3:30, 4:30 ...)   01 2 1 * * 2:01 on the first of every month   I like to use the website https://crontab.guru/ to check my expressions\n\r A continuous function runs all the time, and is best used if you want a webservice or API to run.  \r 1.3 The create function screen For this tutorial I went with a continuous function\nLet us take a look at the differnet elements\n1.3.1 Setup elements Function name\nThis can be whatever you want. The function name will later be converted to a lower-case, \u0026ldquo;-\u0026rdquo; seperated form. Like \u0026ldquo;My awesome FuNcTiOn\u0026rdquo; will become \u0026ldquo;my-awesome-function\u0026rdquo;.\nFunction count\nThis is where scalability comes into play. For now leave function count at 1, but if you later on experience that you need more power, you can easily up-scale your function here.\nPIP requirements\nNow instead of creating a layer for your FAAS function, you can just enter your pip packages here, and it will automatically install them. Easy as that.\nDebian requirements\nAll functions are build in Debian. Meaning you can easily install any Debian package if you need it. If you have installed it on your local system with \u0026ldquo;apt install \u0026hellip;\u0026rdquo; you can list it here. This is useful if you might need some system based tools like imagemagic, wkhtml and others. This is actually not supported yet in other FAAS services.\nVisibility\nYour EasyFAAS function comes with security enabled by default. If your function is public, it will be accessible for everyone. If it is private, you will need to send an auth token to the endpoint. Does that mean you need to create new users and everything? No, you can just get an auth token using our RestAPI using your normal user and password, and then use that token to fire towards your function. Easy as that.\nFunction type\nThere are different functions to choose from. The selection are simple function and storage function.\nThey are distinguishable in the way, that a storage function has persistence, whilst a normal function has not.\nPersistence means that if your function writes data to the disk, it will be safe.\nDo you write or read from a local file? Like a .csv, or .txt file? Then you will need persistence. If your function just calculates and does not write or read anything, you can choose a simple function\n\rPersistence is enabled at the directory /mnt/persistence/, and not in other directories.\nThis means you can still read and write temporary files in both versions, but only persist them if they are written to the /mnt/persistence path.\n\rNo persistence   with open(\"./tmp.txt\", \"w\") as file: file.write(\"my temporary data\") with open(\"./tmp.txt\", \"r\") as file: data = file.read() #   Persistence at /mnt/persistence/   with open(\"./tmp.txt\", \"w\") as file: file.write(\"my temporary data\") with open(\"./tmp.txt\", \"r\") as file: data = file.read() #   \r 1.3.1 Code This is the core part of your function.\nYour function is using FastAPI in the background, but you do not have to worry about much if you use the already inserted starter code:\nfrom fastapi import FastAPI, Request app = FastAPI()  # basic usage @app.get(\u0026#34;/\u0026#34;) async def root():  return {\u0026#34;message\u0026#34;: \u0026#34;Hello World\u0026#34;}  # post requests @app.post(\u0026#34;/\u0026#34;) async def rootPost(request: Request):  data = await request.json()  print(data)  return {\u0026#34;message\u0026#34;: \u0026#34;I got the post: \u0026#34; + str(data)} The EasyFAAS function only supports routing to the root domain \u0026ldquo;/\u0026rdquo;. Meaning if you create different routes they will not be used.\nWhat you can change though, is the request type. It can be GET or POST, as well as the others. For most of the use-cases GET and POST should be enough though.\nIf you want to adapt your code you can easily just add your calculations and functions inside the \u0026ldquo;root\u0026rdquo; function.\nLet us take a look at some examples\nCode example: Bitcoin Price getter  Use a newer browser to see this video.  Previous Video: EasyFAAS Intro\n Let us say you want to create a small route that just returns the current price of Bitcoin. We are using the free coingecko route for it.\nWe will adapt the code to look like this:\nfrom fastapi import FastAPI import requests  base_url = \u0026#34;https://api.binance.com/api/v3\u0026#34;  app = FastAPI()  def getCoingeckoPrice(symbol):  url = base_url + f\u0026#34;/avgPrice?symbol={symbol}USDT\u0026#34;  r = requests.get(url)  return r.json()   # basic usage @app.get(\u0026#34;/\u0026#34;) async def root():  return getCoingeckoPrice(\u0026#34;BTC\u0026#34;) As we want to run this function continuously, and it does not need to save data anywhere, we will choose a continuous and simple function.\nAfter clicking on \u0026ldquo;Deploy\u0026rdquo;, you will be taken back to the mainscreen, where you will see your function.\nThen, click on \u0026ldquo;edit\u0026rdquo; next to you function which will take you to the function detail screen.\nFunction Detail Page We can see a lot of information in here, but let us first just click on the link provided at \u0026ldquo;Link\u0026rdquo;. In this case, it is: https://api.easyfaas.de/functions/route/public/de96cbb3-aead-4485-9889-a76a92a8a719/function-name\nWhen I am clicking on it, it returns:\n{ \u0026#34;status_code\u0026#34;: 200, \u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;{\\\u0026#34;mins\\\u0026#34;: 5, \\\u0026#34;price\\\u0026#34;: \\\u0026#34;19756.28232097\\\u0026#34;}\u0026#34; } The \u0026ldquo;real\u0026rdquo; response of our function is located at the message key in the dictionary. Why is that? We want some kind of check if the request was really successful, or if not, some kind of error message.\nSo if your application is querying your EasyFAAS route, it should always check for the \u0026ldquo;status_code\u0026rdquo; part. If the function is failing, it will return for example code 500 together with an error message in the \u0026ldquo;status\u0026rdquo; part.\nAn example on how your application would query the EasyFAAS route is:\nimport requests  response = requests.get(\u0026#34;https://api.easyfaas.de/functions/route/public/de96cbb3-aead-4485-9889-a76a92a8a719/function-name\u0026#34;) if response.status_code != 200:  raise Exception(\u0026#34;error in EasyFAAS function: \u0026#34; + str(response.text)) else:  response = response.json()  message = json.loads(response[\u0026#34;message\u0026#34;])  print(message)  price = float(message[\u0026#34;price\u0026#34;]) Function Detail Page: Logs If you take a closer look at the function detail page you will see a \u0026ldquo;logs\u0026rdquo; section.\nIn here, everything that your function code returns will be shown. If you refresh the page it will refresh the current logs. If you function is not responsive you will see the reason why in here.\nFunction Detail Page: Metrics Metrics show you how much of the resources your function is using. If you require more \u0026ldquo;power\u0026rdquo;, maybe EasyHost or EasyScale is something for you. Otherwise just contact us.\nEasyFAAS billing You might have read the word \u0026ldquo;credits\u0026rdquo; quite often by now. What does it mean?\nEasyFAAS simplifies billing, in that it charges \u0026ldquo;credits\u0026rdquo; instead of usage-based fees. With other cloud providers, you often do not have the full transparency on what will be charged at the end of the month. There are hidden traffic fees, hidden load balancer fees and way more that you can not foresee unless you run the numbers.\nEasyFAAS solves that, in that it simplifies billing to:\n   Function Type Credit cost per Month Euro value     Simple function 1 2€   Storage function 2 4€   Managed MongoDB 5 10€    No hidden fees, no nothing. In future updates we will even include autoscaling based on the remaining credits in your account, meaning that if you have more credits than functions, and a function is close to it\u0026rsquo;s limit, it will scale up to e.g. 2 functions instead of one.\nBilling is done via Stripe, a secure and reliable payment provider.\n Get Started for free! ","date":"01","image":null,"permalink":"/services/easyfaas/","tags":null,"title":"EasyFAAS"},{"categories":null,"contents":"Use a newer browser to see this video.   --    Source: HIPAA Journal\n Keep your Healthcare applications secure with EasyHealth With an average cost per patient of $429/419€ [1] in the event of a data breach, one does not need to make a lot of calculations to see how essential patient data security should be apart from the moralities.\nWhat do I need to pay attention at? Can I just let someone else do it and not worry about it?\nEasyHealth is your solution\n  Free 15-minute consultation on EasyHealth    Why a managed storage service? The two EasyHealth solutions compared Data privacy issues in the public cloud Pricing  The problems with healthcare data Healthcare data is of much value, and therefore a constant target for hacks. Just imagine the benefit for advertising or insurances, if companies would know about all the illnesses of a person. And especially how much people woud be willing to pay for a snake oil cure that promises instant relief.\nEvil employers would benefit as well, being able to \u0026ldquo;kick out\u0026rdquo; ill or pregnant people in time.\nEven though these are hopefully still science fiction scenarios, you can easily see why hackers target clinics and healthcare providers.\nLet us look at some numbers:\n2,550 data breaches have compromised over 189 million healthcare records in the last decade.\n\r89% of healthcare providers have undergone a data breach.\n\rCyber threats are expected to hit $6 trillion in losses by 2021.\n\rSource\nReasons for breaches Oftentimes the reasons for a databreach can be broken down into:\n Software that is not updated Servers that are not isolated (on-premise) Wrong usage of the public cloud Missing backups Bad networking setups  Usually clinics and healthcare providers focus their time and effort somewhere else, and end up just installing software once, never updating it. Same as your phone and computer updates, the clinic systems should be updated as well to patch new security leaks. There is a whole industry designed to discover new security leaks in applications and software, and sell them as \u0026ldquo;zero day exploits\u0026rdquo; to the highest bidder. Of course these leaks get \u0026ldquo;patched\u0026rdquo;(fixed), but if no one install the update, the well known exploit will always remain open for everyone to use.\nAdditionally, a lot of people do not implement the matching security measures when using the public cloud, leaving ports and machines open for everyone to access.\nLegal challenges when storing patient data Due to these breaches, both the US and EU have implemented strict laws regarding storage of healthcare data.\nIn the US, this protocol is called \u0026ldquo;HIPAA\u0026rdquo;, or \u0026ldquo;Health Insurance Portability and Accountability Act\u0026rdquo; in the longform.\nIn Germany and the EU, these specifications are divided into the general part called \u0026ldquo;GDPR\u0026rdquo; (The General Data Protection Regulation) and further laws defined by each state, like the \u0026ldquo;BayKrG\u0026rdquo; (Bayrisches Krankenhausgesetz).\nEven though there are complex sections, they can be basically summarized for both as:\n1. Encrypting data  Data should always be encrypted both on the disk, as well as in transport (SSL)  2. Let users only see what is necessary  A nurse should only see medical data she needs Someone from accounting should only see \u0026ldquo;numbers\u0026rdquo; etc.  3. Log who edited and saw what  In case there is a breach or violation, you should be able to identify who accessed what  4. Be prepared to report a breach if it happened  You are required by law to submit a report if a breach occurs, in a short amount of time including details that should be prepared beforehand  5. Physically secure servers  Only authorized people should be able to access servers Logging who did what  6. User management system  Automatically expire passwords after time x If an employee leaves the company, his credentials should automatically expire    Free 15-minute assessment on the status of your compliance   What can EasyHealth do for you? Assessment of the status quo\r\rWe can consult you to get a \u0026ldquo;status quo\u0026rdquo; report on what you are already implementing, and where you have areas of improvement. Book a free 15-minute consultation to find out more.\r\r\r\r Compliant Hosting\r\rWith our Hosting services both in the US and Germany, we are offering compliant hosting outside of public cloud providers, providing you a secure and isolated \u0026ldquo;private cloud\u0026rdquo;. Check out EasyHost to learn more, or book a free 15-minute consultation.\r\r\r\r Managed compliant Kubernetes\r\rYou are already well experienced in Kubernetes, but are looking for someone to offer a secure and private Kubernetes hosting solution? You have come to the right place, with EasyKube.\r\r\r\r Managed compliant Databases\r\rWe are offering compliant and secure Postgres (SQL) and MongoDB (NoSQL) databases. Check out EasyDB to learn more, or contact us for other databases that you need to have managed.\r\r\r\r Webapplication programming\r\rWe can create Microservices, Websites and full applications using state-of-the-art tools, all compliant to German or US compliance laws. Book a free 15-minute session to discuss your plans.\r\r\r\r Secure \u0026amp; compliant data archival\r\rYou are just looking for a safe way to archive or store your medical data? Check out EasyStore to learn more, or contact us to discuss your plans.\r\r\r\r   Contact us now to discuss your challenges with healthcare data  ","date":"01","image":null,"permalink":"/services/easyhealth/","tags":null,"title":"EasyHealth"},{"categories":null,"contents":" Use a newer browser to see this video.   The probability of bounce increases 32% as page load time goes from 1 second to 3 seconds Google/SOASTA Research, 2017.\n\rAre your websites and apps giving you a headache? Crashing constantly, being slow? And now it crashed again, rendering your past hours of work useless?\nEasyHost will make hosting your websites and apps easy.\n  Free 15-min consultation on how EasyHost can work for you    What makes EasyHost different? The fall and rise of static sites Why website speed is important EasyHost: Uniting both worlds Portfolio Pricing  What makes EasyHost different? Our secret is simple: Simplicity\nSimplicity both in terms of user experience, as well as in hosting.\nLooking for Website Programming? Head over to Websites\n\rThe fall and rise of static sites Remember the beginning of the web, with their horrible layouts, extreme colors and just pure craziness?\n Amazon back in the day\n The design and usability was horrible, and also just having to change small details of the page required re-loading the whole website, which slows down the user-experience a lot.\nThis is why new technologies like Ajax were invented, to only load tiny parts of information into the website, instead of re-loading the whole deal.\nThe web became more and more dynamic, and WordPress became the dominating CMS for both shops and blogs alike. WordPress introduced huge changes to the web, like being able to just write a blog post, without having to program a whole html website if you wanted a new page to show on your website.\nThis comes with a huge disadvantage though: The server needs to \u0026ldquo;calculate\u0026rdquo; how the final website looks like. You can imagine the WordPress working process like this:\n User opens a website WordPress queries the database to check if we have a blog post for that website If the content exists, load it from the database Grab the \u0026ldquo;Blog posts\u0026rdquo; template and insert that information in there Return the final calculated website to the user  As you can see, this is causing a lot of steps to do for the server, especially if millions of people access the website.\nWhy website speed is important  Sources: LoadStorm\n As you can see above, speed is essential nowadays. Attention is shortlived, and if people have to wait too long for a shop or website to load, they will simply leave.\nNow the big question is: Are they more likely to buy on your fancy WordPress website or on that fast, horrible 90s one?\nUniting both worlds: EasyHost The answer is simple: You can have both.\nRecent websites use Javascript and rely more and more on HTML, which differs from how websites like WordPress work. The main difference is, that new web technologies do the calculations in the browser of the user, opposed to on your server.\nIf we are going back to the example before - this is how EasyHost works:\n User opens a website The browser loads HTML, Javascript and CSS from the server, which are basically just small leightweight text documents These documents contain information how the website looks like, think of it as a blueprint The browser \u0026ldquo;builds\u0026rdquo; the website following the recipe You will see the final result in your browser  Taking it a step further with EasyHost Of course, it is not that simple. Javascript, React and NextJS still query a lot of information from APIs and servers, which adds a lot of delays again, and adds load to your servers. It is better than the \u0026ldquo;old\u0026rdquo; dynamic web, but still kind of slow, especially when scaling.\nLet us say your server has to be located in Germany, with no CDN available for cost and compliance reasons.\nNow even if a user in Australia accesses the website, gets the \u0026ldquo;blueprint\u0026rdquo;, but still needs to query your API for information, loading times become quite slow. Then again, you could add your API servers all over the world, and query only the closest server for that information \u0026hellip; but isn\u0026rsquo;t there a simpler way to do it?\nCan\u0026rsquo;t we just offload the whole work to the users browser?\nThe answer is yes. With EasyHost your websites are basically \u0026ldquo;pre-rendered\u0026rdquo;, like if someone programs a page in pure HTML, offloading the whole work to the users browser. The only information that is queried from your or our server will be the \u0026ldquo;blueprint\u0026rdquo; and images.\nDoes that mean I have to program each page manually? Of course not. You can still use a CMS (content management system) like WordPress, or write text directly in Markdown like I do now, and EasyHost \u0026ldquo;converts\u0026rdquo; this to a nice website and pushes it to the server.\n Writing this text in Markdown\n   Free 15-min consultation on how EasyHost can work for you    Using the CMS\n Some examples of EasyHost in action    Website name Type Example URL     EasyCloudHost.de Company site, Blog, Shop  https://easycloudhost.de/   DataFortress.cloud Company site, Blog  https://datafortress.cloud/   BildBlatt.de WordPress Shop turned static  https://bildblatt.de/   GoodThings4U Complete Static Shop  https://goodthings4u.com/     The advantages of EasyHost / Pricing Now that we know that our websites will load super quick, and our revenues will increase, you will surely tell us that this will cost a hundred bucks a month, right?\nNo. As EasyHost is up to a 1000x lighter on the server you will save a lot of money on hosting.\n  Free 15-min consultation on how EasyHost can work for you  ","date":"01","image":null,"permalink":"/services/easyhost/","tags":null,"title":"EasyHost"},{"categories":null,"contents":" Use a newer browser to see this video.   Your custom private cloud Managed Kubernetes service.\nAre you looking for a way to host your data and applications in a secure, private cloud, out of the hands of big corporations?\nEasyKube is your solution\n  Free Demo to see EasyKube in action!   EasyKube vs other Distributions The advantages of a custom private cloud Top 5 reasons to use a private cloud over the public cloud The simplicity of EasyKube EasyKube in AWS/Google Cloud/Azure Pricing  What is the advantage of using EasyKube over other Kubernetes products?    Feature Default Kubernetes AWS/Azure Kubernetes EasyKube     Standard K8s ✅ ✅ ✅   Load Balancers ❌ ✅ ✅   Easy Node Scaling ❌ ✅ ✅   Volumes ready to use ❌ ✅ ✅   Domain based routing ❌ ❌ ✅   Building Blocks [1] ❌ ❌ ✅   DSGVO \u0026amp; HIPAA compliance ❌ ❌ ✅   \u0026ldquo;Plug \u0026amp; Play\u0026rdquo; ❌ ❌ ✅     [1] Building blocks are ready to use Deployment templates featuring Autoscaling, Security and Persistence\n\r  Free Demo to see EasyKube in action!   The advantages of a custom private cloud So, why should you care to create your own cloud, instead of using public cloud providers?\nThere are several advantages and disadvantages depending on your background. Let us say you store sensitive, intellectual data, like patents or data that gives you a competitive advantage. As you might know, the Patriot Act comes with the problem, that US cloud providers have to give your data to the US government if it is supposed to be linked to terrorism.\nBut even if that is not the case, there are laws for clinics or healthcare providers that force you to host your data in Germany, or at least the EU.\nDoes this mean I have to use a \u0026ldquo;lesser\u0026rdquo; cloud to comply and protect data? \u0026ldquo;lesser\u0026rdquo; is not the case, as Kubernetes is actually offering you a lot of technical advantages over public clouds. Let\u0026rsquo;s find out!\nTop 5 reasons to use a private cloud over the public cloud 1. No vendor lock Public clouds offer you fully integrated products, like serverless functions, that are incompatible with other clouds. Even though it\u0026rsquo;s easy, as they are ready to use in seconds, it comes as a surprise if the cloud provider increases the prices. Should you re-build your whole architecture to fit into another cloud? Or would you rather \u0026ldquo;suck it up\u0026rdquo;, and pay the increased price?\nTo avoid this situation, you should always be able to \u0026ldquo;plug and play\u0026rdquo; your applications, switching providers like your fuel station. This is possible if you are using frameworks like Kubernetes and EasyKube.\nYou are writing your applications as code, called IAAS (infrastructure as code), using barebones Kubernetes yaml files, or more complex Terraform scripts.\nIf the cloud provider increases their rates, you can just move to antother one in seconds.\n2. Your data in your hands In the last 18 months, 79% of companies have experienced at least one cloud data breach; even more alarmingly, 43% have reported 10 or more breaches in that time. Source\n\rMany companies who move to the public cloud have previously hosted their applications and data on a local machine, mostly isolated from the internet. What works in a private, secured room is not working in the public cloud though.\nThis is why many companies leave ports open that should be closed, or access their cloud via insecure channels. A password like \u0026ldquo;Tommie123\u0026rdquo; might work in a local network, where only 30 people have access, but not in the public cloud, where millions of bots constantly scan for security leaks.\nIf you are using EasyKube and Kubernetes, your data runs on your private servers, that you can even completely isolate from the internet if you want. Additionally, EasyKube comes with integrated security features like:\n SSL certificates (Letsencrypt) Automatic HTTPS forwarding (even if you try to run HTTP) Port isolation. Only port 80 and 443 (internet) are open by default  3. No unexpected costs Even though prices seem to be comparable to in-house hosting, the public cloud can cause unexpected costs. This is due to the fact, that oftentimes traffic is charged on top, or logging and monitoring cost extra. All this is automatically integrated if you are using Kubernetes and EasyKube.\nLet us take a look at an example. If you are hosting a website in a virtual instance, the usual price for a 2 vCPU, 2 GB RAM machine is around 10$. This seems okay, but even having ~10.000 visitors a month pushes traffic costs to around 50$, which increases the initial cost of 10$ to 60$ total. And this does not even include backups, logging and monitoring. All this is integrated in Kubernetes and EasyKube by default.\n4. Simplicity Even though public cloud providers offer a huge variety of services, they become quite complex if everything needs to be connected with each other. Let us say you just want to deploy a simple website in a virtual machine.\nIf you are starting the machine, you need to create security groups, networking, permissions, volumes, zones and connections, which are partially unavailable because some services are only supported in some regions\u0026hellip; And then it is throwing an error because your user does not have enough permissions. What permission do I need? \u0026hellip;\nEasyKube saves you a lot of headache, because we are breaking down the complexity. With EasyKube you can actually deploy a whole application, including networking, persistence and domain based routing in less than 80 lines of code, where most is just copy-and-paste.\n5. Cost savings Whilst a public cloud cluster starts at at least 140€ a month, we are starting as low as 10$! Also our general cost is about a tenth of the public cloud Kubernetes cost.\n  Free Demo to see EasyKube in action!   The simplicity of EasyKube Let us take a look at an example to use EasyKube. EasyKube supports:\n Persistent Volumes - backed up to 3 availability zones Horizontal Autoscaling - Scale your applications depending on the load HTTPS by default, with certificates by LetsEncrypt Easy Domain Routing with both our and your custom domain Auto updating Nodes - Avoid security breaches with old nodes Up to Date Kubernetes - Auto-updating Kubernetes Load Balancers - Use load balancers instead of Domain routing if you want Two data centers in Germany - to get reliant nodes. If one data center crashes, your applications will switch over to the second datacenter automatically Additionaly centers in the US and Finland - For global scaling Backups using Velero Custom support - we are always there to help you  EasyKube Deployment example Let us say you have some html code and want to publish it to the web.\nWith EasyKube this comes down to three easy steps\n Build your docker image Copy our starter template Deploy  1. Building your html docker image Dockerfile\nFROM nginx:alpine COPY ./html /var/www/html/ then execute and push to Dockerhub\ndocker build -t easykube/myapp:latest . docker push easykube/myapp:latest \rWe can help you with the building as well - booking our consulting hours\n\rWe also provide private repos hosted in EasyHost. Contact us for more information\n\r2. Copy and paste into our starter template you just need to switch out the \u0026ldquo;image name\u0026rdquo; and give your deployment a name. The namespace will be provided by us.\n# defining our deployment, you basically just need to change the \u0026#34;image name\u0026#34;, \u0026#34;deployment name\u0026#34; and \u0026#34;namespace\u0026#34;. apiVersion: apps/v1 kind: Deployment metadata:  labels:  app: deploymentname  name: deploymentname  namespace: yournamespace(provided) spec:  replicas: 1  selector:  matchLabels:  app: deploymentname  strategy:  type: RollingUpdate  template:  metadata:  labels:  app: deploymentname  spec:  containers:  - image: easykube/myapp:latest  name: deploymentname  ports:  - containerPort: 80  resources: {} status: {} --- apiVersion: v1 kind: Service metadata:  labels:  app: deploymentname  name: deploymentname-service  namespace: yournamespace(provided) spec:  # type: ClusterIP  ports:  - name: \u0026#34;80\u0026#34;  port: 80  targetPort: 80  selector:  app: deploymentname and copy paste your name into the ingress. we also support custom domains.\napiVersion: networking.k8s.io/v1 kind: Ingress metadata:  name: main-ingress  namespace: yournamespace(provided)  annotations:  kubernetes.io/ingress.class: \u0026#34;public\u0026#34;  nginx.ingress.kubernetes.io/ssl-redirect: \u0026#34;true\u0026#34;  nginx.ingress.kubernetes.io/force-ssl-redirect: \u0026#34;true\u0026#34;  nginx.ingress.kubernetes.io/proxy-body-size: \u0026#34;4000m\u0026#34;  nginx.org/client-max-body-size: \u0026#34;4000m\u0026#34;  cert-manager.io/issuer: \u0026#34;letsencrypt-prod\u0026#34; spec:  tls:  - hosts:  - web.easycloudhost.de  secretName: datafortress-tls  rules:  - host: web.easycloudhost.de  http:  paths:  - path: /  pathType: Prefix  backend:  service:  name: deploymentname-service  port:  number: 80 What\u0026rsquo;s happening in the background?\n automatic routing automatic volumes automatic scaling (needs to be set up by us) automatic HTTPS forwarding and free LetEncrypt certificate  3. Deploy kubectl apply -f ./yourfiles/ and DONE\nEasy as that.\n  Free Demo to see EasyKube in action!   And what if I want to host in the public cloud? That is of course possible as well. Just contact us to get an individual offer.\nEasyKube Pricing overview Pricing for EasyKube is offered in two versions:\n The pay-as-you-go pricing, in which you pay per usage, depending on the number of nodes, volumes and load balancers, and The package pricing, which includes improved discounts and additional functionality, but are fixed to 3,6 and 12 months durations.  Package pricing is easier, as it includes Backups, Multi-AZ, Domain based routing and more by default.\n\r1. Pay as you go pricing To achieve resistance, you will need at least 3 servers, but 1 server works as well to just try things out.\n\r   Feature Node XS Node S Node M Node L     Free subdomain of easycloudhost.de ✅ ✅ ✅ ✅   Shared cluster ✅ ❌ ❌ ❌   14 days free trial ✅ ❌ ❌ ❌   vCPU 1 3 4 8   RAM GB 1 4 8 16   Monthly payment 9.99€/m 21.99€/m 42.99€/m 79.99€/m   Comparable price [4] 73$/m + nodes = 103$/m 153$/m 243$/m 893$/m    Prices are automatically converted to your local currency on checkout\n [4] https://calculator.aws/#/addService/EKS\n\rAdditional charges    Feature Price     Volumes [2] 1.50€/m per 10GB   Load Balancer 19.99€/m per piece   Traffic unlimited    [2] 10 GB Minimum, 10 TB Maximum per single volume. Calculated in 10 GB increments\n\r2. Package pricing    Feature EasyKube XS EasyKube S EasyKube M EasyKube L EasyKube Mammoth Custom     Hosting in Germany ✅ ✅ ✅ ✅ ✅ ✅   SSL/HTTPS (letsencrypt) ✅ ✅ ✅ ✅ ✅ ✅   Load Balancers (extra cost) ✅ ✅ ✅ ✅ ✅ ✅   4 TB traffic / m ✅ ✅ ✅ ✅ ✅ ✅   Free subdomain of easycloudhost.de ✅ ✅ ✅ ✅ ✅ ✅   Multi AZ ❌ ❌ ✅ ✅ ✅ ✅   Custom Domain ❌ ❌ ✅ ✅ ✅ ✅   Shared cluster ❌ ❌ ❌ ✅ ✅ ✅   Velero Backups ❌ ❌ ❌ ✅ ✅ ✅   Horizontal Autoscaling ❌ ❌ ❌ ✅ ✅ ✅   Cluster Autoscaling ❌ ❌ ❌ ❌ ✅ ✅   Support extra extra 2h/month 5h/month ✅ ✅   Volumes included [2] 10 GB 20 GB 100 GB 500 GB ✅ ✅   Uptime guarantee ❌ 80% 95% 99% 99.9% ✅   Nr nodes 1 1 3 5 10 100   vCPU total 1 3 9 15 30 300   RAM GB total 1 3 9 20 40 400   Monthly payment 12.99€/m 29.99€/m 79.99€/m 149€/m 2,999€/m Contact us    9€/m | 19€/m | 55.75€/m | 104.20€/m | 2,100€/m | Contact us | -- | Comparable price [4] | 73$/m + nodes = 103$/m | 153$/m | 243$/m | 893$/m | 21.000$/m | custom |\nWe can offer Backups and everything for smaller packages as well, choose \u0026ldquo;custom\u0026rdquo; to get an individual offer\nPrices are automatically converted to your local currency on checkout\n [2] 10 GB Minimum, 10 TB Maximum per single volume\n\r[4] https://calculator.aws/#/addService/EKS\n\r  Free Demo to see EasyKube in action!  ","date":"01","image":null,"permalink":"/services/easykube/","tags":null,"title":"EasyKube"},{"categories":null,"contents":"Use a newer browser to see this video.   -- Deploying and scaling of your Machine Learning Models We are helping you to get your Machine Learning Models up and running, all according to US and German privacy laws.\nKeep your data on your servers, and profit from increased response and load times using autoscaling.\nHead over to EasyScale to find out how we achieve that, or contact us right away to discuss your project with us.\n  Free 15-minute consultation of how we can deploy your Machine Learning Model   Pricing    Package EasyModel S EasyModel M EasyModel L     Max Traffic 1-50 requests a day up to 1000 requests a day, company internal global access   Best for\u0026hellip; Sklearn models TensorFlow Global autoscaling models   Conversion ✅ ✅ ✅   High-Tech Hosting ✅ ✅ ✅   Multi-AZ ❌ ✅ ✅   Basic Auth Protection ❌ ✅ ✅   Autoscaling ❌ ❌ ✅   LDAP/OAuth protection ❌ ❌ ✅   Price [1] 9€/m 99€/m 999€/m    Not sure how much effort it will be? Contact us beforehand\nPrices are automatically converted to your local currency on checkout\n [1] we reserve the right to adjust the package according to the real effort. Should the effort be greater than you expect, we will refund your package and suggest the suitable package, after which you can decide whether to buy it or not.\n\r  Free 15-minute consultation of how we can deploy your Machine Learning Model  ","date":"01","image":null,"permalink":"/services/easymodel/","tags":null,"title":"EasyModel"},{"categories":null,"contents":"Use a newer browser to see this video.   -- Improving speed and reliability of your applications with EasyScale Page load times are important for both your clients and employees. Just a 2 second increase in load times can cause a client to leave your website (source).\nAdditionally, you might have created an application which handled the load of some users just fine, but struggles to keep up with new users?\nEasyScale is your solution\n  Free 15-minute consultation on EasyScale    Top 5 reasons for slow applications How can I scale my application?  Top 5 reasons for slow applications Traditional applications are created as huge, single-application programs. Whilst this is speeding up development, it scales really bad.\n Monolithic vs Microservice architecture. Image by Rancher\n You might be asking yourself: Why is my application or website so slow? Usually it is breaking down to 4 simple reasons.\n1. No Multiprocessing If your application is for example not supporting multiprocessing, it can only run one function at a time. Let us say you are querying a database every time a link is called. If no multiprocessing is used, only one piece of data can be retrieved from the database at a time, with the other ones being \u0026ldquo;on hold\u0026rdquo;.\n2. No Decoupling Additionally, imagine one part of your application failing. Will this block all the other parts until your applications comes back online? If no decoupling is happening the answer is yes.\nThe answer is called decoupling. Decoupling means, you are splitting your application into smaller microservices, that only do one thing, and connect them with a message queue like RabbitMQ, such that one failing part of your application is not affecting other parts.\nAnother nice benefit of this is, that server resources can be distributed to the part where they are required the most right now. Let us say you do not have much traffic on the frontend, as only some users visit your website right now, but a lot of load on backend calculations. In traditional applications each part would only have an equal part of the resources, which means the frontend is idling, whilst the backend is overloaded.\nWhen splitting up your application into Microservices, the load is automatically distributed to where it matters most. Meaning that in our example, the frontend will have fewer resources than the backend, at least for this moment where it is required.\n3. Slow Databases Then, a lot of SQL databases do not support horizontal scaling. This means, that you can only buy a bigger and bigger server, which tends to get quite expensive as only mass-produced servers (smaller ones) are cheap to use. Horizontal scaling means having a lot of \u0026ldquo;smaller\u0026rdquo; servers, that each run the same databases. There are databases that support horizontal scaling, like MongoDB and EasyDB, which can help reduce cost and speed up slow databases.\n4. No distributed computing You should never run software on just one server. If that server is either slow or completely offline, your application will fail.\nThe goal is, to distribute your application over several servers. This can be done with either using a FAAS Framework like EasyFAAS or AWS Lambda, or to use a container management framework like EasyKube or Kubernetes.\nThat way, when one server becomes slow or offline, your applications will automatically be switched to another server.\n5. No autoscaling Closely related to the previous point, there are ways to let your application scale to the demand. This is called autoscaling. Let us take the classic \u0026ldquo;Prime day\u0026rdquo; example. Once a year, Amazon is offering a huge sale, which results in over 100 times the normal server load. Then on other days, like christmas, traffic is almost nonexistent, leaving servers idle.\nThe traditional solution would be, to just buy a huge server that can handle the \u0026ldquo;Prime day\u0026rdquo;. But this causes it to be idle on 90% of the days, causing a lot of unnecessary costs. The other way would be to just \u0026ldquo;ignore\u0026rdquo; traffic peaks and loose those additional customers, which is not ideal either.\nThe answer is to let the Application scale to the current demand. This can be achieved with a FAAS Framework like EasyFAAS or AWS Lambda, or with using a container management framework like EasyKube or Kubernetes.\nHow can I scale my application? EasyScale is a set of the abovementioned services, which will help you to scale your application. Our usual workflow looks like this:\n Free 15 minute consultation on your application An identification workshop to identify weak parts in your application Offer from our side, sorted according to the priority of effectiveness Splitting the application into smaller parts, called Microservices Introducing Message queues to decouple these Microservices, reducing dependencies Using a Framework like FAAS or Kubernetes to distribute the load to multiple servers and support autoscaling Switch to horizontal autoscalable Databases to reduce costs and improve speed   Free 15-minute consultation of how we can scale your application   I just want to get started! Let\u0026rsquo;s get started right away with our packages. Book a package and we will contact you immediately with the next steps.\nThe application is still slow? Get your money back (7 days after completion)!\n   Package EasyScale S EasyScale M EasyScale L EasyScale XL     Analysis Consultation 1 hour 3 hours 1 day 1 week   Best for\u0026hellip; Single Page websites Small blogs, small company websites Online-Shops, Bigger Blogs and company websites Complex architectures that require a backend   Conversion ✅ ✅ ✅ ✅   High-Tech Hosting ✅ ✅ ✅ ✅   Price [1] 99€ 699€ 5,999€ 24,999€    Not sure how much effort it will be? Contact us beforehand\nPrices are automatically converted to your local currency on checkout\n [1] we reserve the right to adjust the package according to the real effort. Should the effort be greater than you expect, we will refund your package and suggest the suitable package, after which you can decide whether to buy it or not.\n\r Free 15-minute consultation of how we can scale your application  ","date":"01","image":null,"permalink":"/services/easyscale/","tags":null,"title":"EasyScale"},{"categories":null,"contents":" Use a newer browser to see this video.   75% of people never scroll past the first page of search engines. 1\n\rConversion rates fall by 4.42% for every extra second that it takes your website to load. 2\n\r86% of people ignore paid banner ads, choosing to only click on organic search results. This is called banner blindness. 3\n\rWe all know that SEO (search-engine-optimization) can be a huge income generator in the Web. The two big sources of traffic remain SEO and SEA (search-engine-advertising), also called paid ads.\nWhat if you could skip on spending hundreds on ads, and instead get traffic and sales for free?\nThis is where SEO comes into play.\nEasySEO will help you to rank higher using Content and on-page optimization that we are doing for you\n  Free 15-min consultation on how EasySEO can work for you    What makes EasySEO different What is the Google SEO ranking bot looking for? Our Portfolio Pricing  What makes EasySEO different? Our secret is simple: Simplicity\nLooking for Website Programming? Head over to Websites\n\rA lot of companies offer SEO nowadays, but many of them remain in the old mindset that only worked years back: repeating your keywords over and over again. But actually, the current Google algorithm is not that simple anymore. It checks a lot for links that are referring to your website, and can quite accuarately, predict if a text was just written for SEO, or is actually helpful.\nWhat is the Google SEO ranking bot looking for? Even though the current algorithm is too complex to summarize, even for Google employees themselves, as it is a complex Machine Learning model, you can break the main checkpoints down to:\n1. Number of links referring to your website, and the importance of the linker  Usually good articles get cited a lot If users share you article, it proves that it must contain good content  2. The time a user remains on your website  measured via analytics or if a users hits the \u0026ldquo;back\u0026rdquo; button and returns to the source slow page loading times can be a false positive for this as well, which is why page speed is important as well. Check out EasyHost to solve this  3. Content quality  the AI model will detect if it is just keywords ideal length: 1400 words ideal structure: many subitems, using metatags and subheadings  Our portfolio We can provide you with all that. We are both running onlineshops, as well as blogs and websites where we generated content to collect a lot of SEO traffic. Page speed is equally important, which is why you will see that our content loads super fast. Check out EasyHost to see how this works.\n   Website Type Example URL     EasyCloudHost.de Company site, Blog, Shop  https://easycloudhost.de/   DataFortress.cloud Company site, Blog  https://datafortress.cloud/   BildBlatt.de WordPress Shop turned static  https://bildblatt.de/   GoodThings4U Complete Static Shop  https://goodthings4u.com/   DeFiGamez Blog, highly content driven  https://defigamez.com/     Our offers Our SEO generated content can be divided into three types:\n High quality content, good for landing pages, homepages and everything etc. Mid quality content, good for subpages, landing pages of smaller products, product descriptions etc. Low quality content, good for blod posts, hidden pages like categories, content below product descriptions etc.  We are also helping you with the on-page SEO optimization, let us dicuss this in a custom call\n   Product EasySEO High Quality EasySEO Mid Quality EasySEO Low Quality Custom     Keyword research ✅ ✅ ✅ ✅   Ideal content structure ✅ ✅ ✅ ✅   Example High-Quality Mid-Quality Low-Quality    English - price per 1000 words 50€ 30€ 10€ Contact us   German - price per 1000 words 90€ 65€ 20€ Contact us    If you need more words just select the multiple of 1,000 words. E.g. if you need 5,000 words, select \u0026ldquo;5\u0026rdquo; as quantity\nPrices are automatically converted to your local currency on checkout\n   Free 15-min consultation on how EasySEO can work for you  ","date":"01","image":null,"permalink":"/services/easyseo/","tags":null,"title":"EasySEO"},{"categories":null,"contents":"Use a newer browser to see this video.   -- Managed S3 compatible Storage You just want an S3 like storage solution, but hosted in Germany/Europe? Or an alternative to OneDrive, Dropbox and Google Drive?\nEasyStore is your solution\n  Free 15-minute consultation on EasyStore    Why a managed storage service? The two EasyStore solutions compared Data privacy issues in the public cloud Pricing  Why a managed storage service? Hosting your own data stroes can be tricky, especially for the following situations:\n FTP is not secure anymore What if someone gives away the user password? With FTP it is hard to set up users What if the storage limit is reached? What if my hard drive is broken? Is my data lost? What if my data gets stolen? What to do if I want to share data?  As you can see, it would be way easier to just use a storage service, and let someone else worry about it. This is why we created EasyStore.\nThe two EasyStore solutions compared    EasyDB Version EasyStore Drive EasyStore S3     UI     Demo Interactive-Demo Interactive-Demo   Best for Humans (GUI) Machines/Code   S3 compatible [1] ❌ ✅   Easy user management ✅ ❌   Open Source base [2] NextCloud MinIO   Closest Public Cloud product Google Drive, MS OneDrive, Dropbox AWS S3, Google Cloud Storage     [1] Use it like you would use S3, e.g. boto3 (Python), s3-node, etc\n\r[2] Open source product before modification into EasyStore\n\rData privacy issues in the public cloud If you are from the financial or health industry, or in general from an industry using sensitive data, you can not have a data breach situation without destroying your business and loosing a lot of customers.\nEasyStore is fully hosted in Germany, and therefore compliant with German and EU based law.\nAnd on top of that EasyStore is giving you:\n Use it like you would use S3 Easy sharing of files in the cloud (EasyStore Drive) Timed links, e.g. expiry after x days User accounts SSL (encryption) Backups custom domain possible    Free 15-minute consultation on EasyStore   EasyStore Pricing overview EasyStore Drive Our secure and simple GUI solution\n   EasyStore Drive solution EasyStore Starter EasyStore Plus EasyStore Teams Custom     Minimum Users 1 1 5 20   Hosting in Germany ✅ ✅ ✅ ✅   SSL/HTTPS (letsencrypt) ✅ ✅ ✅ ✅   Free subdomain of easycloudhost.de ✅ ✅ ✅ ✅   Custom Domain ❌ ✅ ✅ ✅   Dedicated Server ❌ ❌ ✅ ✅   Backups ❌ ❌ ✅ ✅   Support extra extra extra ✅   Uptime guarantee ❌ 95% 95% 99%   Storage per User 5 GB 50 GB 100 GB unlimited   Free Trial 14 days ❌ ❌ ❌   Monthly payment Free Trial (3.99€/m after) 9.99€/m 19.99€/m Contact us    Contact us |Contact us |Contact us |Contact us | -- We can offer Backups and everything for smaller packages as well, choose \u0026ldquo;custom\u0026rdquo; to get an individual offer\nPrices are automatically converted to your local currency on checkout\n   Free Demo to see EasyStore in action!   EasyStore S3 Our secure and simple S3 compatible solution\n   EasyStore S3 solution EasyStore Starter EasyStore Plus EasyStore Teams Custom     Max. Buckets 1 ∞ ∞ ∞   Hosting in Germany ✅ ✅ ✅ ✅   SSL/HTTPS (letsencrypt) ✅ ✅ ✅ ✅   Free subdomain of easycloudhost.de ✅ ✅ ✅ ✅   Custom Domain ❌ ✅ ✅ ✅   Dedicated Server ❌ ❌ ✅ ✅   Backups ❌ ❌ ✅ ✅   Support extra extra extra ✅   Uptime guarantee ❌ 95% 95% 99%   Storage per User 1 GB 10 GB 50 GB unlimited   Free Trial 14 days ❌ ❌ ❌   Monthly payment 3.99€/m 9.99€/m 39.99€/m Contact us    Contact us |Contact us |Contact us |Contact us | -- We can offer Backups and everything for smaller packages as well, choose \u0026ldquo;custom\u0026rdquo; to get an individual offer\nPrices are automatically converted to your local currency on checkout\n   Free Demo to see EasyStore in action!  ","date":"01","image":null,"permalink":"/services/easystore/","tags":null,"title":"EasyStore"},{"categories":null,"contents":"","date":"01","image":null,"permalink":"/faq/","tags":null,"title":"FAQ's"},{"categories":null,"contents":"","date":"01","image":null,"permalink":"/how-it-works/","tags":null,"title":"How It Works"},{"categories":null,"contents":"EasyCloudHost.de is a website and brand of\nDataFortress.cloud UG Georgenstraße 13 86152 Augsburg Germany DE345185498\nIBAN: DE39110101015994728316 BIC/SWIFT: SOBKDEB2XXX\n","date":"01","image":null,"permalink":"/impressum/","tags":null,"title":"Impressum"},{"categories":null,"contents":"This section includes documents covering the legal terms that apply to various aspects of our operation and services. All our subsidiaries will follow rules that are aligned with the documentation presented below, adapted for the specifics of its particular jurisdiction.\nConsumer Loan Procedures Terms and conditions that govern consumer loan services offered by us or our subsidiaries, including general\u0026hellip;  Terms of Use Terms and conditions that govern consumer loan services offered by us or our subsidiaries, including general\u0026hellip;  Privacy Policy Terms and conditions that govern consumer loan services offered by us or our subsidiaries, including general\u0026hellip;   ","date":"01","image":null,"permalink":"/legal/","tags":null,"title":"Legal and Compliance"},{"categories":null,"contents":"Interested in a custom solution or need help setting up EasyServices?\nNot sure what is right for you? Contact us before buying to get a free 15 minute consultation.\nJunior Developers79€/hourWeb and App ProjectsPythonData Science and EngineeringBook nowSenior Developer129€/hourComplex Web and App ProjectsData EngineeringDeep LearningDevOpsKubernetes \u0026amp; CloudMicroservicesBook nowExpert / Justin249€/hourData EngineeringFinance Deep LearningComplex KubernetesMicroservicesDistributed ComputingBook nowMultipleCustomBroad Developer NetworkGerman company \u0026amp; invoice incl. VATProject ManagementWorkshopsSCRUM sprintsHigh-Tech solutionsBook now","date":"01","image":null,"permalink":"/pricing/","tags":null,"title":"Pricing"},{"categories":null,"contents":"EasyCloudHost.de is a website and brand of DataFortress.cloud UG.\nWe are very delighted that you have shown interest in our enterprise. Data protection is of a particularly high priority for the management of DataFortress.cloud. The use of the Internet pages of DataFortress.cloud is possible without any indication of personal data; however, if a data subject wants to use special enterprise services via our website, processing of personal data could become necessary. If the processing of personal data is necessary and there is no statutory basis for such processing, we generally obtain consent from the data subject.\nThe processing of personal data, such as the name, address, e-mail address, or telephone number of a data subject shall always be in line with the General Data Protection Regulation (GDPR), and in accordance with the country-specific data protection regulations applicable to DataFortress.cloud. By means of this data protection declaration, our enterprise would like to inform the general public of the nature, scope, and purpose of the personal data we collect, use and process. Furthermore, data subjects are informed, by means of this data protection declaration, of the rights to which they are entitled.\nAs the controller, DataFortress.cloud has implemented numerous technical and organizational measures to ensure the most complete protection of personal data processed through this website. However, Internet-based data transmissions may in principle have security gaps, so absolute protection may not be guaranteed. For this reason, every data subject is free to transfer personal data to us via alternative means, e.g. by telephone.\nDefinitions The data protection declaration of DataFortress.cloud is based on the terms used by the European legislator for the adoption of the General Data Protection Regulation (GDPR). Our data protection declaration should be legible and understandable for the general public, as well as our customers and business partners. To ensure this, we would like to first explain the terminology used. In this data protection declaration, we use, inter alia, the following terms:\na) Personal data Personal data means any information relating to an identified or identifiable natural person (“data subject”). An identifiable natural person is one who can be identified, directly or indirectly, in particular by reference to an identifier such as a name, an identification number, location data, an online identifier or to one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person.\nb) Data subject Data subject is any identified or identifiable natural person, whose personal data is processed by the controller responsible for the processing.\nc) Processing Processing is any operation or set of operations which is performed on personal data or on sets of personal data, whether or not by automated means, such as collection, recording, organisation, structuring, storage, adaptation or alteration, retrieval, consultation, use, disclosure by transmission, dissemination or otherwise making available, alignment or combination, restriction, erasure or destruction.\nd) Restriction of processing Restriction of processing is the marking of stored personal data with the aim of limiting their processing in the future.\ne) Profiling Profiling means any form of automated processing of personal data consisting of the use of personal data to evaluate certain personal aspects relating to a natural person, in particular to analyse or predict aspects concerning that natural person’s performance at work, economic situation, health, personal preferences, interests, reliability, behaviour, location or movements.\nf) Pseudonymisation Pseudonymisation is the processing of personal data in such a manner that the personal data can no longer be attributed to a specific data subject without the use of additional information, provided that such additional information is kept separately and is subject to technical and organisational measures to ensure that the personal data are not attributed to an identified or identifiable natural person.\ng) Controller or controller responsible for the processing Controller or controller responsible for the processing is the natural or legal person, public authority, agency or other body which, alone or jointly with others, determines the purposes and means of the processing of personal data; where the purposes and means of such processing are determined by Union or Member State law, the controller or the specific criteria for its nomination may be provided for by Union or Member State law.\nh) Processor Processor is a natural or legal person, public authority, agency or other body which processes personal data on behalf of the controller.\ni) Recipient Recipient is a natural or legal person, public authority, agency or another body, to which the personal data are disclosed, whether a third party or not. However, public authorities which may receive personal data in the framework of a particular inquiry in accordance with Union or Member State law shall not be regarded as recipients; the processing of those data by those public authorities shall be in compliance with the applicable data protection rules according to the purposes of the processing.\nj) Third party Third party is a natural or legal person, public authority, agency or body other than the data subject, controller, processor and persons who, under the direct authority of the controller or processor, are authorised to process personal data.\nk) Consent Consent of the data subject is any freely given, specific, informed and unambiguous indication of the data subject’s wishes by which he or she, by a statement or by a clear affirmative action, signifies agreement to the processing of personal data relating to him or her.\nName and Address of the controller Controller for the purposes of the General Data Protection Regulation (GDPR), other data protection laws applicable in Member states of the European Union and other provisions related to data protection is: DataFortress.cloud\nSchönbrunner Straße 266\n1120 Vienna\nAustria\nPhone: +43 677 61178288\nEmail: info@datafortress.cloud Website: https://www.datafotress.cloud\nCookies The Internet pages of DataFortress.cloud use cookies. Cookies are text files that are stored in a computer system via an Internet browser.\nCookie\tDescription\tDuration\tType _ga\tThis cookie is installed by Google Analytics. The cookie is used to calculate visitor, session, campaign data and keep track of site usage for the site’s analytics report. The cookies store information anonymously and assign a randomly generated number to identify unique visitors.\t2 years\tAnalytics _gid\tThis cookie is installed by Google Analytics. The cookie is used to store information of how visitors use a website and helps in creating an analytics report of how the wbsite is doing. The data collected including the number visitors, the source where they have come from, and the pages viisted in an anonymous form.\t1 day\tAnalytics _gat\tThis cookies is installed by Google Universal Analytics to throttle the request rate to limit the colllection of data on high traffic sites.\t1 minute\tPerformance CookieScriptConsent\tNeeded to track cookie choice\t1 day\tPerformance Many Internet sites and servers use cookies. Many cookies contain a so-called cookie ID. A cookie ID is a unique identifier of the cookie. It consists of a character string through which Internet pages and servers can be assigned to the specific Internet browser in which the cookie was stored. This allows visited Internet sites and servers to differentiate the individual browser of the dats subject from other Internet browsers that contain other cookies. A specific Internet browser can be recognized and identified using the unique cookie ID.\nThrough the use of cookies, DataFortress.cloud can provide the users of this website with more user-friendly services that would not be possible without the cookie setting.\nBy means of a cookie, the information and offers on our website can be optimized with the user in mind. Cookies allow us, as previously mentioned, to recognize our website users. The purpose of this recognition is to make it easier for users to utilize our website. The website user that uses cookies, e.g. does not have to enter access data each time the website is accessed, because this is taken over by the website, and the cookie is thus stored on the user’s computer system. Another example is the cookie of a shopping cart in an online shop. The online store remembers the articles that a customer has placed in the virtual shopping cart via a cookie.\nThe data subject may, at any time, prevent the setting of cookies through our website by means of a corresponding setting of the Internet browser used, and may thus permanently deny the setting of cookies. Furthermore, already set cookies may be deleted at any time via an Internet browser or other software programs. This is possible in all popular Internet browsers. If the data subject deactivates the setting of cookies in the Internet browser used, not all functions of our website may be entirely usable.\nCollection of general data and information The website of DataFortress.cloud collects a series of general data and information when a data subject or automated system calls up the website. This general data and information are stored in the server log files. Collected may be (1) the browser types and versions used, (2) the operating system used by the accessing system, (3) the website from which an accessing system reaches our website (so-called referrers), (4) the sub-websites, (5) the date and time of access to the Internet site, (6) an Internet protocol address (IP address), (7) the Internet service provider of the accessing system, and (8) any other similar data and information that may be used in the event of attacks on our information technology systems. When using these general data and information, DataFortress.cloud does not draw any conclusions about the data subject. Rather, this information is needed to (1) deliver the content of our website correctly, (2) optimize the content of our website as well as its advertisement, (3) ensure the long-term viability of our information technology systems and website technology, and (4) provide law enforcement authorities with the information necessary for criminal prosecution in case of a cyber-attack. Therefore, DataFortress.cloud analyzes anonymously collected data and information statistically, with the aim of increasing the data protection and data security of our enterprise, and to ensure an optimal level of protection for the personal data we process. The anonymous data of the server log files are stored separately from all personal data provided by a data subject.\nSubscription to our newsletters On the website of DataFortress.cloud, users are given the opportunity to subscribe to our enterprise’s newsletter. The input mask used for this purpose determines what personal data are transmitted, as well as when the newsletter is ordered from the controller. DataFortress.cloud informs its customers and business partners regularly by means of a newsletter about enterprise offers. The enterprise’s newsletter may only be received by the data subject if (1) the data subject has a valid e-mail address and (2) the data subject registers for the newsletter shipping. A confirmation e-mail will be sent to the e-mail address registered by a data subject for the first time for newsletter shipping, for legal reasons, in the double opt-in procedure. This confirmation e-mail is used to prove whether the owner of the e-mail address as the data subject is authorized to receive the newsletter.\nDuring the registration for the newsletter, we also store the IP address of the computer system assigned by the Internet service provider (ISP) and used by the data subject at the time of the registration, as well as the date and time of the registration. The collection of this data is necessary in order to understand the (possible) misuse of the e-mail address of a data subject at a later date, and it therefore serves the aim of the legal protection of the controller.\nThe personal data collected as part of a registration for the newsletter will only be used to send our newsletter. In addition, subscribers to the newsletter may be informed by e-mail, as long as this is necessary for the operation of the newsletter service or a registration in question, as this could be the case in the event of modifications to the newsletter offer, or in the event of a change in technical circumstances. There will be no transfer of personal data collected by the newsletter service to third parties. The subscription to our newsletter may be terminated by the data subject at any time. The consent to the storage of personal data, which the data subject has given for shipping the newsletter, may be revoked at any time. For the purpose of revocation of consent, a corresponding link is found in each newsletter. It is also possible to unsubscribe from the newsletter at any time directly on the website of the controller, or to communicate this to the controller in a different way.\nNewsletter-Tracking The newsletter of DataFortress.cloud contains so-called tracking pixels. A tracking pixel is a miniature graphic embedded in such e-mails, which are sent in HTML format to enable log file recording and analysis. This allows a statistical analysis of the success or failure of online marketing campaigns. Based on the embedded tracking pixel, DataFortress.cloud may see if and when an e-mail was opened by a data subject, and which links in the e-mail were called up by data subjects. Such personal data collected in the tracking pixels contained in the newsletters are stored and analyzed by the controller in order to optimize the shipping of the newsletter, as well as to adapt the content of future newsletters even better to the interests of the data subject. These personal data will not be passed on to third parties. Data subjects are at any time entitled to revoke the respective separate declaration of consent issued by means of the double-opt-in procedure. After a revocation, these personal data will be deleted by the controller. DataFortress.cloud automatically regards a withdrawal from the receipt of the newsletter as a revocation.\nContact possibility via the website The website of DataFortress.cloud contains information that enables a quick electronic contact to our enterprise, as well as direct communication with us, which also includes a general address of the so-called electronic mail (e-mail address). If a data subject contacts the controller by e-mail or via a contact form, the personal data transmitted by the data subject are automatically stored. Such personal data transmitted on a voluntary basis by a data subject to the data controller are stored for the purpose of processing or contacting the data subject. There is no transfer of this personal data to third parties.\nComments function in the blog on the website DataFortress.cloud offers users the possibility to leave individual comments on individual blog contributions on a blog, which is on the website of the controller. A blog is a web-based, publicly-accessible portal, through which one or more people called bloggers or web-bloggers may post articles or write down thoughts in so-called blogposts. Blogposts may usually be commented by third parties.\nIf a data subject leaves a comment on the blog published on this website, the comments made by the data subject are also stored and published, as well as information on the date of the commentary and on the user’s (pseudonym) chosen by the data subject. In addition, the IP address assigned by the Internet service provider (ISP) to the data subject is also logged. This storage of the IP address takes place for security reasons, and in case the data subject violates the rights of third parties, or posts illegal content through a given comment. The storage of these personal data is, therefore, in the own interest of the data controller, so that he can exculpate in the event of an infringement. This collected personal data will not be passed to third parties, unless such a transfer is required by law or serves the aim of the defense of the data controller.\nSubscription to comments in the blog on the website The comments made in the blog of DataFortress.cloud may be subscribed to by third parties. In particular, there is the possibility that a commenter subscribes to the comments following his comments on a particular blog post. If a data subject decides to subscribe to the option, the controller will send an automatic confirmation e-mail to check the double opt-in procedure as to whether the owner of the specified e-mail address decided in favor of this option. The option to subscribe to comments may be terminated at any time.\nRoutine erasure and blocking of personal data The data controller shall process and store the personal data of the data subject only for the period necessary to achieve the purpose of storage, or as far as this is granted by the European legislator or other legislators in laws or regulations to which the controller is subject to. If the storage purpose is not applicable, or if a storage period prescribed by the European legislator or another competent legislator expires, the personal data are routinely blocked or erased in accordance with legal requirements.\nRights of the data subject a) Right of confirmation Each data subject shall have the right granted by the European legislator to obtain from the controller the confirmation as to whether or not personal data concerning him or her are being processed. If a data subject wishes to avail himself of this right of confirmation, he or she may, at any time, contact any employee of the controller. b) Right of access Each data subject shall have the right granted by the European legislator to obtain from the controller free information about his or her personal data stored at any time and a copy of this information. Furthermore, the European directives and regulations grant the data subject access to the following information:\nthe purposes of the processing; the categories of personal data concerned; the recipients or categories of recipients to whom the personal data have been or will be disclosed, in particular recipients in third countries or international organisations; where possible, the envisaged period for which the personal data will be stored, or, if not possible, the criteria used to determine that period; the existence of the right to request from the controller rectification or erasure of personal data, or restriction of processing of personal data concerning the data subject, or to object to such processing; the existence of the right to lodge a complaint with a supervisory authority; where the personal data are not collected from the data subject, any available information as to their source; the existence of automated decision-making, including profiling, referred to in Article 22(1) and (4) of the GDPR and, at least in those cases, meaningful information about the logic involved, as well as the significance and envisaged consequences of such processing for the data subject. Furthermore, the data subject shall have a right to obtain information as to whether personal data are transferred to a third country or to an international organisation. Where this is the case, the data subject shall have the right to be informed of the appropriate safeguards relating to the transfer.\nIf a data subject wishes to avail himself of this right of access, he or she may, at any time, contact any employee of the controller.\nc) Right to rectification Each data subject shall have the right granted by the European legislator to obtain from the controller without undue delay the rectification of inaccurate personal data concerning him or her. Taking into account the purposes of the processing, the data subject shall have the right to have incomplete personal data completed, including by means of providing a supplementary statement.\nIf a data subject wishes to exercise this right to rectification, he or she may, at any time, contact any employee of the controller.\nd) Right to erasure (Right to be forgotten) Each data subject shall have the right granted by the European legislator to obtain from the controller the erasure of personal data concerning him or her without undue delay, and the controller shall have the obligation to erase personal data without undue delay where one of the following grounds applies, as long as the processing is not necessary:\nThe personal data are no longer necessary in relation to the purposes for which they were collected or otherwise processed. The data subject withdraws consent to which the processing is based according to point (a) of Article 6(1) of the GDPR, or point (a) of Article 9(2) of the GDPR, and where there is no other legal ground for the processing. The data subject objects to the processing pursuant to Article 21(1) of the GDPR and there are no overriding legitimate grounds for the processing, or the data subject objects to the processing pursuant to Article 21(2) of the GDPR. The personal data have been unlawfully processed. The personal data must be erased for compliance with a legal obligation in Union or Member State law to which the controller is subject. The personal data have been collected in relation to the offer of information society services referred to in Article 8(1) of the GDPR. If one of the aforementioned reasons applies, and a data subject wishes to request the erasure of personal data stored by DataFortress.cloud, he or she may, at any time, contact any employee of the controller. An employee of DataFortress.cloud shall promptly ensure that the erasure request is complied with immediately.\nWhere the controller has made personal data public and is obliged pursuant to Article 17(1) to erase the personal data, the controller, taking account of available technology and the cost of implementation, shall take reasonable steps, including technical measures, to inform other controllers processing the personal data that the data subject has requested erasure by such controllers of any links to, or copy or replication of, those personal data, as far as processing is not required. An employees of DataFortress.cloud will arrange the necessary measures in individual cases.\ne) Right of restriction of processing Each data subject shall have the right granted by the European legislator to obtain from the controller restriction of processing where one of the following applies:\nThe accuracy of the personal data is contested by the data subject, for a period enabling the controller to verify the accuracy of the personal data. The processing is unlawful and the data subject opposes the erasure of the personal data and requests instead the restriction of their use instead. The controller no longer needs the personal data for the purposes of the processing, but they are required by the data subject for the establishment, exercise or defence of legal claims. The data subject has objected to processing pursuant to Article 21(1) of the GDPR pending the verification whether the legitimate grounds of the controller override those of the data subject. If one of the aforementioned conditions is met, and a data subject wishes to request the restriction of the processing of personal data stored by DataFortress.cloud, he or she may at any time contact any employee of the controller. The employee of DataFortress.cloud will arrange the restriction of the processing.\nf) Right to data portability Each data subject shall have the right granted by the European legislator, to receive the personal data concerning him or her, which was provided to a controller, in a structured, commonly used and machine-readable format. He or she shall have the right to transmit those data to another controller without hindrance from the controller to which the personal data have been provided, as long as the processing is based on consent pursuant to point (a) of Article 6(1) of the GDPR or point (a) of Article 9(2) of the GDPR, or on a contract pursuant to point (b) of Article 6(1) of the GDPR, and the processing is carried out by automated means, as long as the processing is not necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller.\nFurthermore, in exercising his or her right to data portability pursuant to Article 20(1) of the GDPR, the data subject shall have the right to have personal data transmitted directly from one controller to another, where technically feasible and when doing so does not adversely affect the rights and freedoms of others.\nIn order to assert the right to data portability, the data subject may at any time contact any employee of DataFortress.cloud.\ng) Right to object Each data subject shall have the right granted by the European legislator to object, on grounds relating to his or her particular situation, at any time, to processing of personal data concerning him or her, which is based on point (e) or (f) of Article 6(1) of the GDPR. This also applies to profiling based on these provisions.\nDataFortress.cloud shall no longer process the personal data in the event of the objection, unless we can demonstrate compelling legitimate grounds for the processing which override the interests, rights and freedoms of the data subject, or for the establishment, exercise or defence of legal claims.\nIf DataFortress.cloud processes personal data for direct marketing purposes, the data subject shall have the right to object at any time to processing of personal data concerning him or her for such marketing. This applies to profiling to the extent that it is related to such direct marketing. If the data subject objects to DataFortress.cloud to the processing for direct marketing purposes, DataFortress.cloud will no longer process the personal data for these purposes.\nIn addition, the data subject has the right, on grounds relating to his or her particular situation, to object to processing of personal data concerning him or her by DataFortress.cloud for scientific or historical research purposes, or for statistical purposes pursuant to Article 89(1) of the GDPR, unless the processing is necessary for the performance of a task carried out for reasons of public interest.\nIn order to exercise the right to object, the data subject may contact any employee of DataFortress.cloud. In addition, the data subject is free in the context of the use of information society services, and notwithstanding Directive 2002/58/EC, to use his or her right to object by automated means using technical specifications.\nh) Automated individual decision-making, including profiling Each data subject shall have the right granted by the European legislator not to be subject to a decision based solely on automated processing, including profiling, which produces legal effects concerning him or her, or similarly significantly affects him or her, as long as the decision (1) is not is necessary for entering into, or the performance of, a contract between the data subject and a data controller, or (2) is not authorised by Union or Member State law to which the controller is subject and which also lays down suitable measures to safeguard the data subject’s rights and freedoms and legitimate interests, or (3) is not based on the data subject’s explicit consent.\nIf the decision (1) is necessary for entering into, or the performance of, a contract between the data subject and a data controller, or (2) it is based on the data subject’s explicit consent, DataFortress.cloud shall implement suitable measures to safeguard the data subject’s rights and freedoms and legitimate interests, at least the right to obtain human intervention on the part of the controller, to express his or her point of view and contest the decision.\nIf the data subject wishes to exercise the rights concerning automated individual decision-making, he or she may, at any time, contact any employee of DataFortress.cloud.\ni) Right to withdraw data protection consent Each data subject shall have the right granted by the European legislator to withdraw his or her consent to processing of his or her personal data at any time.\nIf the data subject wishes to exercise the right to withdraw the consent, he or she may, at any time, contact any employee of DataFortress.cloud.\nData protection provisions about the application and use of Facebook On this website, the controller has integrated components of the enterprise Facebook. Facebook is a social network. A social network is a place for social meetings on the Internet, an online community, which usually allows users to communicate with each other and interact in a virtual space. A social network may serve as a platform for the exchange of opinions and experiences, or enable the Internet community to provide personal or business-related information. Facebook allows social network users to include the creation of private profiles, upload photos, and network through friend requests.\nThe operating company of Facebook is Facebook, Inc., 1 Hacker Way, Menlo Park, CA 94025, United States. If a person lives outside of the United States or Canada, the controller is the Facebook Ireland Ltd., 4 Grand Canal Square, Grand Canal Harbour, Dublin 2, Ireland.\nWith each call-up to one of the individual pages of this Internet website, which is operated by the controller and into which a Facebook component (Facebook plug-ins) was integrated, the web browser on the information technology system of the data subject is automatically prompted to download display of the corresponding Facebook component from Facebook through the Facebook component. An overview of all the Facebook Plug-ins may be accessed under https://developers.facebook.com/docs/plugins/. During the course of this technical procedure, Facebook is made aware of what specific sub-site of our website was visited by the data subject.\nIf the data subject is logged in at the same time on Facebook, Facebook detects with every call-up to our website by the data subject—and for the entire duration of their stay on our Internet site—which specific sub-site of our Internet page was visited by the data subject. This information is collected through the Facebook component and associated with the respective Facebook account of the data subject. If the data subject clicks on one of the Facebook buttons integrated into our website, e.g. the “Like” button, or if the data subject submits a comment, then Facebook matches this information with the personal Facebook user account of the data subject and stores the personal data.\nFacebook always receives, through the Facebook component, information about a visit to our website by the data subject, whenever the data subject is logged in at the same time on Facebook during the time of the call-up to our website. This occurs regardless of whether the data subject clicks on the Facebook component or not. If such a transmission of information to Facebook is not desirable for the data subject, then he or she may prevent this by logging off from their Facebook account before a call-up to our website is made.\nThe data protection guideline published by Facebook, which is available at https://facebook.com/about/privacy/, provides information about the collection, processing and use of personal data by Facebook. In addition, it is explained there what setting options Facebook offers to protect the privacy of the data subject. In addition, different configuration options are made available to allow the elimination of data transmission to Facebook. These applications may be used by the data subject to eliminate a data transmission to Facebook.\nData protection provisions about the application and use of functions of the Amazon Partner program On this website, the controller has integrated Amazon components as a participant in the Amazon partner program. The Amazon components were created by Amazon with the aim to mediate customers through advertisements on various websites of the Amazon group, in particular Amazon.co.uk, Local.Amazon.co.uk, Amazon.de, BuyVIP.com, Amazon.de, Amazon.it and Amazon.es in return for the payment of a commission. By using the Amazon components, the controller may generate advertising revenue. The operating company of this Amazon component is Amazon EU S.à.r.l, 5 Rue Plaetis, L-2338 Luxembourg, Luxembourg.\nAmazon sets a cookie the information technology system of the data subject. The definition of cookies is explained above. With each single call-up to one of the individual pages of this Internet website, which is operated by the controller and in which an Amazon component was integrated, the Internet browser on the information technology system of the data subject will automatically submit data for the purpose of online advertising and the settlement of commissions to Amazon through the respective Amazon component. During the course of this technical procedure, Amazon receives personal information that is used to trace the origin of orders from Amazon, and as a result, to allow the accounting of a commission. Among other things, Amazon may understand that the data subject has clicked on an affiliate link on our website.\nThe data subject may, as stated above, prevent the setting of cookies through our website at any time by means of a corresponding adjustment of the web browser used, and thus permanently deny the setting of cookies. Such an adjustment to the Internet browser used would also prevent Amazon from setting a cookie on the information technology system of the data subject. In addition, cookies already in use by Amazon may be deleted at anytime via a web browser or other software programs.\nFurther information and the actual data protection provisions of Amazon may be retrieved under https://www.amazon.de/gp/help/customer/display.html?nodeId=3312401\u0026amp;language=en_GB.\nData protection provisions about the application and use of Google Analytics (with anonymization function) On this website, the controller has integrated the component of Google Analytics (with the anonymizer function). Google Analytics is a web analytics service. Web analytics is the collection, gathering, and analysis of data about the behavior of visitors to websites. A web analysis service collects, inter alia, data about the website from which a person has come (the so-called referrer), which sub-pages were visited, or how often and for what duration a sub-page was viewed. Web analytics are mainly used for the optimization of a website and in order to carry out a cost-benefit analysis of Internet advertising. The operator of the Google Analytics component is Google Ireland Limited, Gordon House, Barrow Street, Dublin, D04 E5W5, Ireland.\nFor the web analytics through Google Analytics the controller uses the application “_gat. _anonymizeIp”. By means of this application the IP address of the Internet connection of the data subject is abridged by Google and anonymised when accessing our websites from a Member State of the European Union or another Contracting State to the Agreement on the European Economic Area.\nThe purpose of the Google Analytics component is to analyze the traffic on our website. Google uses the collected data and information, inter alia, to evaluate the use of our website and to provide online reports, which show the activities on our websites, and to provide other services concerning the use of our Internet site for us.\nGoogle Analytics places a cookie on the information technology system of the data subject. The definition of cookies is explained above. With the setting of the cookie, Google is enabled to analyze the use of our website. With each call-up to one of the individual pages of this Internet site, which is operated by the controller and into which a Google Analytics component was integrated, the Internet browser on the information technology system of the data subject will automatically submit data through the Google Analytics component for the purpose of online advertising and the settlement of commissions to Google. During the course of this technical procedure, the enterprise Google gains knowledge of personal information, such as the IP address of the data subject, which serves Google, inter alia, to understand the origin of visitors and clicks, and subsequently create commission settlements.\nThe cookie is used to store personal information, such as the access time, the location from which the access was made, and the frequency of visits of our website by the data subject. With each visit to our Internet site, such personal data, including the IP address of the Internet access used by the data subject, will be transmitted to Google in the United States of America. These personal data are stored by Google in the United States of America. Google may pass these personal data collected through the technical procedure to third parties.\nThe data subject may, as stated above, prevent the setting of cookies through our website at any time by means of a corresponding adjustment of the web browser used and thus permanently deny the setting of cookies. Such an adjustment to the Internet browser used would also prevent Google Analytics from setting a cookie on the information technology system of the data subject. In addition, cookies already in use by Google Analytics may be deleted at any time via a web browser or other software programs.\nIn addition, the data subject has the possibility of objecting to a collection of data that are generated by Google Analytics, which is related to the use of this website, as well as the processing of this data by Google and the chance to preclude any such. For this purpose, the data subject must download a browser add-on under the link https://tools.google.com/dlpage/gaoptout and install it. This browser add-on tells Google Analytics through a JavaScript, that any data and information about the visits of Internet pages may not be transmitted to Google Analytics. The installation of the browser add-ons is considered an objection by Google. If the information technology system of the data subject is later deleted, formatted, or newly installed, then the data subject must reinstall the browser add-ons to disable Google Analytics. If the browser add-on was uninstalled by the data subject or any other person who is attributable to their sphere of competence, or is disabled, it is possible to execute the reinstallation or reactivation of the browser add-ons.\nFurther information and the applicable data protection provisions of Google may be retrieved under https://www.google.com/intl/en/policies/privacy/ and under http://www.google.com/analytics/terms/us.html. Google Analytics is further explained under the following Link https://www.google.com/analytics/.\nData protection provisions about the application and use of Google-AdWords On this website, the controller has integrated Google AdWords. Google AdWords is a service for Internet advertising that allows the advertiser to place ads in Google search engine results and the Google advertising network. Google AdWords allows an advertiser to pre-define specific keywords with the help of which an ad on Google’s search results only then displayed, when the user utilizes the search engine to retrieve a keyword-relevant search result. In the Google Advertising Network, the ads are distributed on relevant web pages using an automatic algorithm, taking into account the previously defined keywords. The operating company of Google AdWords is Google Ireland Limited, Gordon House, Barrow Street, Dublin, D04 E5W5, Ireland.\nThe purpose of Google AdWords is the promotion of our website by the inclusion of relevant advertising on the websites of third parties and in the search engine results of the search engine Google and an insertion of third-party advertising on our website.\nIf a data subject reaches our website via a Google ad, a conversion cookie is filed on the information technology system of the data subject through Google. The definition of cookies is explained above. A conversion cookie loses its validity after 30 days and is not used to identify the data subject. If the cookie has not expired, the conversion cookie is used to check whether certain sub-pages, e.g, the shopping cart from an online shop system, were called up on our website. Through the conversion cookie, both Google and the controller can understand whether a person who reached an AdWords ad on our website generated sales, that is, executed or canceled a sale of goods.\nThe data and information collected through the use of the conversion cookie is used by Google to create visit statistics for our website. These visit statistics are used in order to determine the total number of users who have been served through AdWords ads to ascertain the success or failure of each AdWords ad and to optimize our AdWords ads in the future. Neither our company nor other Google AdWords advertisers receive information from Google that could identify the data subject.\nThe conversion cookie stores personal information, e.g. the Internet pages visited by the data subject. Each time we visit our Internet pages, personal data, including the IP address of the Internet access used by the data subject, is transmitted to Google in the United States of America. These personal data are stored by Google in the United States of America. Google may pass these personal data collected through the technical procedure to third parties.\nThe data subject may, at any time, prevent the setting of cookies by our website, as stated above, by means of a corresponding setting of the Internet browser used and thus permanently deny the setting of cookies. Such a setting of the Internet browser used would also prevent Google from placing a conversion cookie on the information technology system of the data subject. In addition, a cookie set by Google AdWords may be deleted at any time via the Internet browser or other software programs.\nThe data subject has a possibility of objecting to the interest based advertisement of Google. Therefore, the data subject must access from each of the browsers in use the link www.google.de/settings/ads and set the desired settings.\nFurther information and the applicable data protection provisions of Google may be retrieved under https://www.google.com/intl/en/policies/privacy/.\nData protection provisions about the application and use of Instagram On this website, the controller has integrated components of the service Instagram. Instagram is a service that may be qualified as an audiovisual platform, which allows users to share photos and videos, as well as disseminate such data in other social networks. The operating company of the services offered by Instagram is Facebook Ireland Ltd., 4 Grand Canal Square, Grand Canal Harbour, Dublin 2 Ireland.\nWith each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which an Instagram component (Insta button) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to the download of a display of the corresponding Instagram component of Instagram. During the course of this technical procedure, Instagram becomes aware of what specific sub-page of our website was visited by the data subject.\nIf the data subject is logged in at the same time on Instagram, Instagram detects with every call-up to our website by the data subject—and for the entire duration of their stay on our Internet site—which specific sub-page of our Internet page was visited by the data subject. This information is collected through the Instagram component and is associated with the respective Instagram account of the data subject. If the data subject clicks on one of the Instagram buttons integrated on our website, then Instagram matches this information with the personal Instagram user account of the data subject and stores the personal data.\nInstagram receives information via the Instagram component that the data subject has visited our website provided that the data subject is logged in at Instagram at the time of the call to our website. This occurs regardless of whether the person clicks on the Instagram button or not. If such a transmission of information to Instagram is not desirable for the data subject, then he or she can prevent this by logging off from their Instagram account before a call-up to our website is made.\nFurther information and the applicable data protection provisions of Instagram may be retrieved under https://help.instagram.com/155833707900388 and https://www.instagram.com/about/legal/privacy/.\nData protection provisions about the application and use of LinkedIn The controller has integrated components of the LinkedIn Corporation on this website. LinkedIn is a web-based social network that enables users with existing business contacts to connect and to make new business contacts. Over 400 million registered people in more than 200 countries use LinkedIn. Thus, LinkedIn is currently the largest platform for business contacts and one of the most visited websites in the world. The operating company of LinkedIn is LinkedIn Corporation, 2029 Stierlin Court Mountain View, CA 94043, UNITED STATES. For privacy matters outside of the UNITED STATES LinkedIn Ireland, Privacy Policy Issues, Wilton Plaza, Wilton Place, Dublin 2, Ireland, is responsible.\nWith each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a LinkedIn component (LinkedIn plug-in) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to the download of a display of the corresponding LinkedIn component of LinkedIn. Further information about the LinkedIn plug-in may be accessed under https://developer.linkedin.com/plugins. During the course of this technical procedure, LinkedIn gains knowledge of what specific sub-page of our website was visited by the data subject.\nIf the data subject is logged in at the same time on LinkedIn, LinkedIn detects with every call-up to our website by the data subject—and for the entire duration of their stay on our Internet site—which specific sub-page of our Internet page was visited by the data subject. This information is collected through the LinkedIn component and associated with the respective LinkedIn account of the data subject. If the data subject clicks on one of the LinkedIn buttons integrated on our website, then LinkedIn assigns this information to the personal LinkedIn user account of the data subject and stores the personal data.\nLinkedIn receives information via the LinkedIn component that the data subject has visited our website, provided that the data subject is logged in at LinkedIn at the time of the call-up to our website. This occurs regardless of whether the person clicks on the LinkedIn button or not. If such a transmission of information to LinkedIn is not desirable for the data subject, then he or she may prevent this by logging off from their LinkedIn account before a call-up to our website is made.\nLinkedIn provides under https://www.linkedin.com/psettings/guest-controls the possibility to unsubscribe from e-mail messages, SMS messages and targeted ads, as well as the ability to manage ad settings. LinkedIn also uses affiliates such as Eire, Google Analytics, BlueKai, DoubleClick, Nielsen, Comscore, Eloqua, and Lotame. The setting of such cookies may be denied under https://www.linkedin.com/legal/cookie-policy. The applicable privacy policy for LinkedIn is available under https://www.linkedin.com/legal/privacy-policy. The LinkedIn Cookie Policy is available under https://www.linkedin.com/legal/cookie-policy.\nData protection provisions about the application and use of YouTube On this website, the controller has integrated components of YouTube. YouTube is an Internet video portal that enables video publishers to set video clips and other users free of charge, which also provides free viewing, review and commenting on them. YouTube allows you to publish all kinds of videos, so you can access both full movies and TV broadcasts, as well as music videos, trailers, and videos made by users via the Internet portal. The operating company of YouTube is Google Ireland Limited, Gordon House, Barrow Street, Dublin, D04 E5W5, Ireland.\nWith each call-up to one of the individual pages of this Internet site, which is operated by the controller and on which a YouTube component (YouTube video) was integrated, the Internet browser on the information technology system of the data subject is automatically prompted to download a display of the corresponding YouTube component. Further information about YouTube may be obtained under https://www.youtube.com/yt/about/en/. During the course of this technical procedure, YouTube and Google gain knowledge of what specific sub-page of our website was visited by the data subject.\nIf the data subject is logged in on YouTube, YouTube recognizes with each call-up to a sub-page that contains a YouTube video, which specific sub-page of our Internet site was visited by the data subject. This information is collected by YouTube and Google and assigned to the respective YouTube account of the data subject.\nYouTube and Google will receive information through the YouTube component that the data subject has visited our website, if the data subject at the time of the call to our website is logged in on YouTube; this occurs regardless of whether the person clicks on a YouTube video or not. If such a transmission of this information to YouTube and Google is not desirable for the data subject, the delivery may be prevented if the data subject logs off from their own YouTube account before a call-up to our website is made.\nYouTube’s data protection provisions, available at https://www.google.com/intl/en/policies/privacy/, provide information about the collection, processing and use of personal data by YouTube and Google.\nLegal basis for the processing Art. 6(1) lit. a GDPR serves as the legal basis for processing operations for which we obtain consent for a specific processing purpose. If the processing of personal data is necessary for the performance of a contract to which the data subject is party, as is the case, for example, when processing operations are necessary for the supply of goods or to provide any other service, the processing is based on Article 6(1) lit. b GDPR. The same applies to such processing operations which are necessary for carrying out pre-contractual measures, for example in the case of inquiries concerning our products or services. Is our company subject to a legal obligation by which processing of personal data is required, such as for the fulfillment of tax obligations, the processing is based on Art. 6(1) lit. c GDPR. In rare cases, the processing of personal data may be necessary to protect the vital interests of the data subject or of another natural person. This would be the case, for example, if a visitor were injured in our company and his name, age, health insurance data or other vital information would have to be passed on to a doctor, hospital or other third party. Then the processing would be based on Art. 6(1) lit. d GDPR. Finally, processing operations could be based on Article 6(1) lit. f GDPR. This legal basis is used for processing operations which are not covered by any of the abovementioned legal grounds, if processing is necessary for the purposes of the legitimate interests pursued by our company or by a third party, except where such interests are overridden by the interests or fundamental rights and freedoms of the data subject which require protection of personal data. Such processing operations are particularly permissible because they have been specifically mentioned by the European legislator. He considered that a legitimate interest could be assumed if the data subject is a client of the controller (Recital 47 Sentence 2 GDPR).\nThe legitimate interests pursued by the controller or by a third party Where the processing of personal data is based on Article 6(1) lit. f GDPR our legitimate interest is to carry out our business in favor of the well-being of all our employees and the shareholders.\nPeriod for which the personal data will be stored The criteria used to determine the period of storage of personal data is the respective statutory retention period. After expiration of that period, the corresponding data is routinely deleted, as long as it is no longer necessary for the fulfillment of the contract or the initiation of a contract.\nProvision of personal data as statutory or contractual requirement; Requirement necessary to enter into a contract; Obligation of the data subject to provide the personal data; possible consequences of failure to provide such data We clarify that the provision of personal data is partly required by law (e.g. tax regulations) or can also result from contractual provisions (e.g. information on the contractual partner). Sometimes it may be necessary to conclude a contract that the data subject provides us with personal data, which must subsequently be processed by us. The data subject is, for example, obliged to provide us with personal data when our company signs a contract with him or her. The non-provision of the personal data would have the consequence that the contract with the data subject could not be concluded. Before personal data is provided by the data subject, the data subject must contact any employee. The employee clarifies to the data subject whether the provision of the personal data is required by law or contract or is necessary for the conclusion of the contract, whether there is an obligation to provide the personal data and the consequences of non-provision of the personal data.\nExistence of automated decision-making As a responsible company, we do not use automatic decision-making or profiling.\nThis Privacy Policy has been generated by the Privacy Policy Generator of the DGD – Your External DPO that was developed in cooperation with German Lawyers from WILDE BEUGER SOLMECKE, Cologne.\n","date":"01","image":null,"permalink":"/privacy-policy/","tags":null,"title":"Privacy \u0026 Policy"},{"categories":null,"contents":"Our customer portal is currently under maintenance :( Please create a ticket below and we will manually cancel / edit any subscriptions:\n","date":"01","image":null,"permalink":"/subscription-management/","tags":null,"title":"Subscription management"},{"categories":null,"contents":"General Terms and Conditions of DataFortress.cloud UG Preamble: DataFortress.cloud UG (hereinafter \u0026ldquo;DataFortress\u0026rdquo;), Georgenstraße 13, 86152 Augsburg, offers services in the field of web hosting. The customer (hereinafter referred to as the \u0026ldquo;Customer\u0026rdquo;) wishes to make use of these services under the following contractual conditions.\n1 Conclusion of Contract and Scope 1.1 The content of the service/services owed by DataFortress in detail results from the appendices to this contract. The quantitative scope of the services is variable and can be flexibly changed by the Customer (see Section 11 below). The offers of DataFortress are not directed at consumers within the meaning of § 13 BGB (German Civil Code).\n1.2 The contract is concluded by DataFortress accepting the order placed by the customer on the basis of the respective offer of DataFortress by order confirmation by e-mail (hereinafter referred to as \u0026ldquo;the contract\u0026rdquo; regardless of singular or plural).\n1.3 These contractual terms and conditions apply exclusively to the contractual relationship between DataFortress and the Customer. General terms and conditions of the Customer shall not apply. Counter-confirmations of the customer with reference to its own terms and conditions are expressly rejected, insofar as such terms and conditions deviate from the present contractual terms or contain provisions that are contrary to them.\n2 Subject matter of the contract 2.1 The subject matter of the contract is the provision of computer capacity, storage space (server hosting) and the making available of data for permanent retrieval from the Internet (web hosting) depending on the individual agreement between the parties in accordance with the annex hosting concept/offer/service certificate. The customer is obligated to accept the minimum quantity regulated in the Annex Hosting Concept/Offer/Service Certificate. In addition, DataFortress offers services that support or supplement the hosting and that the Customer can book separately.\n2.2 Depending on the selected tariff and (optionally) the selected Service Level Agreement (\u0026ldquo;SLA\u0026rdquo;), the Customer shall be provided with dedicated or virtualized servers without or with software and various performance features defined in more detail in Annex Hosting Concept/Offer/Service Certificate.\n2.3 The SLA selected by the Customer is to be taken from the appendices of the respective valid Service Level Agreements and product-specific Service Level Agreements, if applicable.\n2.4 The customer shall receive access data to its customer front end, in which it can view how much power it is using. These access data must always be kept secret and may not be made available to third parties. If Customer becomes aware of any unauthorized use of its access data, Customer shall inform DataFortress immediately. The customer is solely responsible for all activities in connection with his access data.\nhosting services 3.1 DataFortress keeps the data stored by the customer in accordance with the contract (in particular his website) permanently, worldwide and basically publicly accessible on the Internet via the network maintained by DataFortress and the Internet connected to it. DataFortress does not assume any responsibility for the success of the respective access to the website, unless exclusively the network operated by DataFortress including the interfaces to third party networks maintained by DataFortress is concerned.  3.2 The customer receives access to the server of DataFortress to the extent defined between the parties. For this purpose, DataFortress provides him with appropriate certificates. The certificates are to be kept secret at all times and may not be made available to unauthorized third parties. Furthermore, they are personalized, but a customer may receive several personalized access authorizations upon request in order to allow employees access. The customer will inform DataFortress immediately if third parties have obtained his access data. In individual cases, companies affiliated with the customer are also considered third parties. The customer is solely responsible for all activities in connection with the certificates made available to him.\n3.3 DataFortress enables the client to view the traffic, which is the basis for billing, via the client front end. The statistics are the basis of the monthly traffic billing, which includes the external traffic.\n4 Use of Software 4.1 As far as DataFortress provides software, this is done at the interface of the data network, within which the software runs, to other networks. The software, the computing power required for its use and the necessary storage and data processing space are provided by DataFortress. The software remains on servers for which DataFortress is responsible. DataFortress is not responsible for establishing and maintaining the data connection between the Customer\u0026rsquo;s IT system and the aforementioned transfer point.\n4.2 Insofar as the software runs exclusively on the servers of DataFortress or of a service provider commissioned by DataFortress, the Customer does not require any copyright usage rights to the software, nor does DataFortress grant any such rights. However, DataFortress grants the Customer, for the term of the agreement, the non-exclusive, non-transferable right, limited in time to the term of the user agreement, to load the user interface of the software for display on the screen into the main memory of the end devices used for this purpose in accordance with the agreement and to make the resulting reproductions of the user interface.\n4.3 With respect to DataFortress software, the customer acquires the right to access DataFortress software to the extent stipulated in the contract during the term of the contract and to use it for the purposes stipulated in the contract.\n5 Availability 5.1 The availability of the servers, if applicable, the software and the data paths up to the transfer point to the Internet is 99.5% per year less the time required for the installation of updates, upgrades, new releases and/or other modifications, unless otherwise agreed in the appendices to the respective valid Service Level Agreements and product-specific Service Level Agreements.\n5.2 DataFortress draws the Customer\u0026rsquo;s attention to the fact that restrictions or impairments of the services provided may arise that are beyond DataFortress\u0026rsquo; control. This includes, in particular, actions of third parties not acting on behalf of DataFortress, technical conditions of the Internet that cannot be influenced by DataFortress as well as force majeure. Also the hardware and software or technical infrastructure used by the customer can have an influence on the services of DataFortress. Insofar as such circumstances have an influence on the availability or functionality of the service provided by DataFortress, this has no effect on the contractual conformity of the services provided.\n5.3 The Customer is obligated to notify DataFortress immediately and as precisely as possible of any functional failures, malfunctions or impairments. If the Customer fails to do so, § 536 c BGB shall apply accordingly.\n6 Incident Management 6.1 An incident is deemed to exist if servers or software do not fulfill the contractual functions.\n6.2 Notifications of support incidents shall be made via a ticket system, which can also be accessed at info@datafortress.cloud. Emergencies must also be reported by telephone at +49 160 1136770 in order to ensure prompt support.\n6.3 DataFortress provides support services, unless Customer has selected a more extensive SLA, only on Mondays to Fridays between 8:00 a.m. and 5:00 p.m. (\u0026ldquo;Service Hours\u0026rdquo;).\n6.4 The user reporting a support case shall provide a description of the respective support case as detailed as possible with each report in order to enable DataFortress to eliminate the error as efficiently as possible.\ndomain registration 7.1 As far as DataFortress takes over the domain registration for the customer, DataFortress registers the ordered domains at the responsible registry. The parties agree that DataFortress neither owes a domain search nor the success of the registration procedure.  7.2 DataFortress does not carry out any legal or content-related examination of the domains to be registered. In particular, DataFortress does not assume any examination as to whether and to what extent a registration is actually or legally possible and permissible. The customer has to carry out the corresponding checks himself or have them carried out. The customer is responsible for checking which registration rules apply at the respective registry.\nrights to individual work results Insofar as DataFortress develops individually protectable contents for the customer (for example scripts or certificates), DataFortress grants the customer an exclusive right of use to the order results individually developed and/or provided for the customer (\u0026ldquo;work results\u0026rdquo;). DataFortress transfers to the customer the exclusive, content, temporally and spatially unlimited and irrevocable right of use to these work results for all known and unknown types of use, including the right to process the work results in any way.  9 Obligations of the Customer 9.1 The Customer undertakes vis-à-vis DataFortress to perform the acts of cooperation required for the provision of the agreed services. In particular, the customer shall provide all necessary information and documents free of charge and shall designate a contact person who is professionally qualified and has sufficient authorizations for the performance of the contract. Submitted information and documents serve as an essential basis for the implementation services of DataFortress. The provision of incorrect or incomplete information shall be at the Customer\u0026rsquo;s expense.\n9.2 The Customer shall itself back up data and information, including those processed on IT systems for which DataFortress is responsible. In addition, DataFortress will create daily backups for VEs, which will be kept for seven days, weekly backups, which will be kept for four weeks and monthly backups, which will be kept for three months. Data on shared storage systems (e.g., NFS servers), will be backed up daily and the backups will be retained for three days, provided that the backup of the data does not exceed 20 hours.\n9.3 If DataFortress receives materials, data and other information (\u0026ldquo;Customer Materials\u0026rdquo;) from the Customer in the course of the performance of the Agreement, the Customer shall ensure that a copy of the data remains with the Customer for backup purposes. The Customer shall also ensure that data stored on DataFortress\u0026rsquo; systems are free of any malware.\n9.4 Insofar as the Customer provides DataFortress with protected content (e.g. graphics, trademarks and other content protected by copyright or trademark law), the Customer shall grant DataFortress all rights necessary for the performance of the contractual agreement. This includes, in particular, the right to make the relevant content available to the public. In this context, the customer assures that he owns all necessary rights to customer materials provided in order to grant DataFortress the corresponding rights.\n9.5 DataFortress shall be released from the obligation to provide the contractual services if and to the extent that the Customer fails to comply with its duties to cooperate. Any existing schedules shall be automatically adjusted accordingly. If the Customer is responsible for the failure to provide the cooperation service and if DataFortress suffers damage as a result, the Customer shall compensate DataFortress for such damage.\nexemption 10.1 As a technical service provider, DataFortress stores content and data for the Customer, which the Customer enters and stores and makes available for retrieval when using the contractual services. The Customer undertakes vis-à-vis DataFortress not to post any content and data that is punishable by law or otherwise illegal in absolute terms or in relation to individual third parties. The customer remains the responsible party with regard to personal data and must therefore always check whether the processing of such data via the use of the software is supported by the corresponding permissions.  10.2 The Customer is solely responsible for all content and processed data made available by it as well as any legal positions required for this. DataFortress does not take any notice of contents of the customer and does not check them in any respect.\n10.3 In this context, Customer agrees to indemnify DataFortress against any liability and any costs, including possible and actual costs of legal proceedings, in the event that a claim is made against DataFortress by third parties, including employees of Customer personally, as a result of alleged acts or omissions of Customer. DataFortress shall notify the Customer of the claim and, to the extent legally possible, give the Customer the opportunity to defend the asserted claim. At the same time, the Customer shall immediately provide DataFortress with all information available to it regarding the facts that are the subject of the claim in full.\n10.4 Any further claims for damages shall remain unaffected.\nchanges in the subject matter of the contract (change request procedure) 11.1 Changes in the quantitative scope of the services owed in accordance with the Annex Hosting Concept/Offer/Service Certificate (e.g. with regard to the storage space used, number of CPU cores or amount of RAM as well as the number of systems of a type (e.g. app server, database slave server, etc.) may be made by the Customer himself or have them made by DataFortress at any time. Such change requests are to be sent directly to the Service Desk via Ticket System by e-mail to info@datafortress.cloud. Change requests are accepted on weekdays, Monday through Friday between 9:00 a.m. and 5:00 p.m. and documented in the ticket system.  11.2 Changes to the content of the owed service (e.g. the use of additional offers) can also be ordered via the ticket system.\nSuch a change request shall contain at least the following information:\nDescription of the desired change; Meaning and purpose of the requested change; Special circumstances and background to be considered with regard to the requested change; Urgency of the requested change.\n11.3 DataFortress shall then immediately check what effects the desired change will have on the contractual service structure, in particular with regard to the agreed remuneration. If DataFortress determines that the change request can be implemented without further ado, the change will be implemented and documented in the ticket system.\n11.4 If DataFortress determines that services to be rendered cannot be performed or can only be performed with a delay due to the expected review effort for the change, DataFortress shall notify the customer of this and point out to the customer that the change request can only be further reviewed if the affected services are postponed accordingly. If the customer declares his agreement with this postponement, DataFortress will carry out the review of the change request. If, on the other hand, the customer withdraws its change request, the initiated change request procedure ends.\n11.5 To the extent that the change request cannot be implemented immediately and without additional consultation with the customer, DataFortress shall, after reviewing the change request, present to the customer the effects of the change request on the agreements made. The explanation shall contain either a proposal for the implementation of the change request or information as to why the change request cannot be implemented. The parties shall immediately agree on the content of a proposal for the implementation of the change request and fix the result of a successful agreement in a supplementary agreement. If no agreement is reached or if the change request procedure ends for any other reason, the original service content and scope shall remain in effect. (Such supplements only exist in exceptional cases. The business is too dynamic for that in many cases).\n11.6 The customer shall bear the expenses incurred as a result of the change request. This includes in particular the expenses for the examination of the change request, the preparation of a change proposal and any downtimes. The applicable hourly rate for this shall be based on the price list valid at the time of the conclusion of the contract.\n11.7 DataFortress is entitled to change or deviate from the scope of its services in order to ensure the provision of its services under this agreement and, in particular, to release larger volumes, even without a previously explicitly issued order by the customer. DataFortress will notify the customer of such changes immediately after they are made. After notification, the customer may reject the changes or deviations or additionally provided services. If the customer does not object to the changes or deviations after corresponding notification by DataFortress within two weeks after receipt of the notification, DataFortress will invoice the services rendered according to the respective valid price list. If the Customer does not object in text form within the aforementioned period, the change, deviation or additionally rendered service shall be deemed approved.\n11.8 If the catalog of services has to be changed due to an act of cooperation not undertaken by the Customer, in particular due to the correction of information already provided up to the time of acceptance or as a result of the subsequent submission of information, this shall be deemed to be a change in services in accordance with this Section 11.\n12 Remuneration; payment and invoicing modalities 12.1 Invoicing shall be based on the volume used or the services booked. Booked resources such as servers as well as agreed flat rates shall be invoiced monthly in advance, services which are invoiced according to consumption, such as traffic, shall be invoiced subsequently. The prices are based on the price list valid at the time of the conclusion of the contract.\n12.2 Unless otherwise indicated, prices quoted by DataFortress are subject to the applicable statutory value-added tax. The remuneration is based on the price list valid at the time of the conclusion of the contract. Additional services which are subject to a charge and which the customer makes use of after conclusion of the contract shall be remunerated in accordance with the price list valid at that time or in accordance with the agreement of the parties.\n12.3 If a fixed price is agreed as a one-time payment, it shall be due for payment without a discount upon receipt of the invoice. If payment of the fixed price in installments is agreed, the agreed installment shall be due for payment upon receipt of the partial invoice without any further discount.\n12.4 If the agreed service is remunerated on a time and material basis, the invoice shall be issued monthly in arrears for the previous month. The invoice shall be issued on the basis of written proof of performance, which shall be attached to the invoice. Services that are billed on a time basis, e.g. in the area of Managed Services, are documented by DataFortress with the smallest unit of 15 minutes. The performance records are considered accepted if the Client does not object to them within a maximum of 5 working days after receipt.\n12.5 In the case of term contracts, DataFortress can adjust the prices as well as the rates for an agreed remuneration according to the general price development after the expiry of the initially agreed contract term. If the fee increase amounts to more than 5%, the customer may terminate the contractual relationship with a notice period of five working days. The notice of termination shall be given within 14 days after the announcement of the increase.\n12.6 In the case of agreed partial services and for partial invoices, the provisions of this Section 12 shall apply accordingly.\n12.7 Invoices shall be sent electronically as PDF files. A fee shall be charged for mailing. Invoices shall be due for payment without deduction immediately upon receipt. The conditions and consequences of default shall be governed by the statutory provisions. If a due payment of a customer is more than three months overdue or has been reminded for the third time, DataFortress reserves the right to discontinue its own services or to block access to the service. If a partial amount of an invoice is disputed, the undisputed part shall always be paid.\n12.8 Both contracting parties are only entitled to set-off with legally established or undisputed claims that are due and such that arise from the same legal relationship and have arisen from a claim that would have entitled the creditor of the counterclaim to assert a right of retention or a right to refuse performance.\n13 Liability 13.1 DataFortress is liable for damages of the Customer caused intentionally or by gross negligence, which are the consequence of the non-existence of a guaranteed quality of the object of performance, which are based on a culpable violation of essential contractual obligations (so-called cardinal obligations, see Section 13.2), which are the consequence of culpable injury to health, body or life or for which liability is provided for under the Product Liability Act, in accordance with the statutory provisions.\n13.2 Cardinal obligations are those contractual obligations the fulfillment of which makes the proper execution of the contract possible in the first place and the observance of which the contractual partner may regularly rely on, and the violation of which on the other hand endangers the achievement of the purpose of the contract.\n13.3 In the event of a breach of a cardinal obligation, liability - insofar as the damage is based solely on simple negligence and does not affect life, limb or health - is limited to such damage that is foreseeable and can typically be expected to occur within the scope of contracts such as those between DataFortress and the Customer.\n13.4 Liability due to interruption, malfunction or other events causing damage, which are based on telecommunication services of DataFortress or third parties for which DataFortress is liable, is limited to the amount of recourse possible for DataFortress against the respective telecommunication service provider. DataFortress is not liable for the operability of the connection lines to the contractual server, in case of power failures and in case of failures of servers which are not within the sphere of influence of DataFortress.\n13.5 Claims for loss of profit are excluded.\n13.6 In all other respects, liability - for whatever legal reason - of DataFortress as well as of its vicarious agents and assistants is excluded.\n13.7 DataFortress\u0026rsquo; liability for loss of data is limited to the typical recovery effort that could not have been avoided even if the customer had made regular and risk-appropriate backup copies.\nsubcontractors, third party products DataFortress may use subcontractors for the provision of the services owed. In doing so, DataFortress ensures that the service provision in the area of hosting is carried out from Germany.  15 Confidentiality 15.1 The Customer is obligated to keep confidential all information about DataFortress that has become known to him or becomes known to him in connection with this contract and that is marked as confidential or is classified as business and trade secrets on the basis of other circumstances (e.g. conception and implementation of the programming carried out by DataFortress and other technical and technological know-how of DataFortress, hereinafter referred to as \u0026ldquo;Confidential Information\u0026rdquo;), to keep it permanently secret, not to disclose it to third parties, to record it or to use it in any other way, unless DataFortress has expressly consented in writing to its disclosure or use or the information is required to be disclosed by law, court order or administrative decision.\n15.2 Insofar as relevant, the Customer shall ensure by means of suitable contractual agreements with its employees and all other persons working for it that these persons also refrain from any disclosure, utilization, disclosure or recording of the Confidential Information.\n15.3 The information shall not be Confidential Information within the meaning of this Section 15 if it was\nwas already known to the Customer beforehand without the information having been subject to a confidentiality obligation, is generally known or becomes known without a breach of the confidentiality obligations assumed, is disclosed to the Customer by a third party without breach of a confidentiality obligation. 15.4 If the Customer violates any of the obligations set forth in this clause, DataFortress may terminate the contract extraordinarily. DataFortress reserves the right to further and more extensive claims, in particular claims for damages.\n15.5 The obligations under this clause 15 shall survive the end of the contract.\n reference information DataFortress is entitled to refer to services to be rendered or rendered for the customer on its own website and in its own documents when stating references for advertising purposes and to also use the logo and the company name (abbreviated if necessary) of the customer for this purpose. Furthermore, DataFortress is allowed to publish press releases about the client\u0026rsquo;s order and the project.\n  data protection 17.1 Insofar as DataFortress collects, processes and uses personal data from the sphere of the Customer in the course of initiating, establishing and executing the contract, this shall be done in accordance with the applicable statutory provisions on data protection, and in particular only within the scope of the purpose of the contract.\n  17.2 The Customer shall not process any personal data on IT systems for which DataFortress is technically responsible. If the Customer commissions DataFortress with services in the context of which it cannot be excluded that DataFortress comes into contact with personal data for which the Customer is responsible, a commissioned data processing agreement shall be concluded.\n18 Term, Termination 18.1 Unless otherwise agreed for individual services, the minimum term of the contract shall be 24 months after signing of the contract. The term shall be extended by a further twelve months in each case if the contract is not terminated in writing after expiry of the minimum contract term with six months\u0026rsquo; notice to the end of the month.\n18.2 Notwithstanding the foregoing, this Agreement may be terminated in writing by either party in the event of a sustained breach of material contractual obligations by the other party if, despite written warning by the other party, such party fails to comply with the Agreement even after a reasonable period of time and the terminating party cannot reasonably be expected to continue the respective contractual relationship until the ordinary termination as set forth above takes effect.\n18.3 The right to extraordinary termination shall remain unaffected.\n19 Termination and settlement 19.1 In the event of a complete or partial termination of this agreement, DataFortress is obligated to surrender to the Customer or to destroy at the Customer\u0026rsquo;s request all data, documents and materials in its possession which contain business, organizational or technical data or information from or about the Customer, unless statutory retention periods conflict with this, unless the data, documents, etc. to be surrendered or destroyed are the intellectual property of DataFortress or are still required by DataFortress for the further processing of the agreement.\n19.2 At the Customer\u0026rsquo;s request, DataFortress shall provide all services required for the transfer of the contractual services to the Customer or a third party designated by the Customer (e.g. migration to another IT system, provision of appropriately qualified employees, performance of training) for a period of up to twelve (12) months after termination of the Agreement (hereinafter referred to as the \u0026ldquo;Transition Period\u0026rdquo;). DataFortress shall work closely with the Customer and the third party designated by the Customer to ensure that no disruptions in the provision of services occur during the Transition Period and that the Customer or the third party designated by the Customer is able to commence operation of the contractual services after the date of termination of the Agreement. In this respect, DataFortress is also obligated to prepare and provide appropriate documentation. The Customer shall cooperate in this regard.\n19.3 DataFortress\u0026rsquo;s claim to remuneration for the monthly fee as well as all other costs shall remain in effect until the final shutdown of the systems. In individual cases, a reduction of the calendar monthly remuneration, the agreed availability levels and the warranty conditions may be agreed for this period.\n19.4 Upon receipt of written notification that the Customer has been able to read and process all transferred data, the data will be deleted from the systems in DataFortress\u0026rsquo; data center and the Customer will be notified of this deletion in writing.\nnon-solicitation Customer agrees to refrain from employing or soliciting or attempting to employ or solicit any employee employed or otherwise engaged by DataFortress for the duration of this Agreement.  21 Miscellaneous 21.1 The place of performance of all obligations under the respective contract shall be the place of business of DataFortress if the Customer is a merchant within the meaning of the German Commercial Code (HGB), a legal entity under public law or a special fund under public law.\n21.2 The law of the Federal Republic of Germany shall apply exclusively to the contract. The application of German international private law and the EU regulations ROM I and ROM II is excluded.\n21.3 The place of jurisdiction for all disputes arising directly or indirectly from or in connection with the contractual relationship shall be Augsburg if the Customer is a merchant within the meaning of the German Commercial Code (HGB), a legal entity under public law or a special fund under public law. This shall also apply in the context of proceedings relating to bills of exchange and checks.\n21.4 If any provision in these General Terms and Conditions, the Special Terms and Conditions or any other contractual document is or becomes invalid, the validity of all other provisions shall not be affected.\n","date":"01","image":null,"permalink":"/terms/","tags":null,"title":"Terms \u0026 Conditions"},{"categories":null,"contents":"Subscribe now to get a download link for the \u0026ldquo;Top 7 Kubernetes Security Misconceptions and Myths Download\u0026rdquo; PDF!\nOur newsletter informs you about all the news regarding Kubernetes, Cloud and Data! Unsubscribe any time.\n#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:600px;} /* Add your own Mailchimp form style overrides in your site stylesheet or in this style block. We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */  #mc-embedded-subscribe-form input[type=checkbox]{display: inline; width: auto;margin-right: 10px;} #mergeRow-gdpr {margin-top: 20px;} #mergeRow-gdpr fieldset label {font-weight: normal;} #mc-embedded-subscribe-form .mc_fieldset{border:none;min-height: 0px;padding-bottom:0px;}  Subscribe \u0026 Download! * indicates required Email Address *   First Name   Last Name   Phone Number   Contact me regarding EasyServices  EasyKube EasyHost EasyFAAS Other   Marketing Permissions Please select all the ways you would like to hear from DataFortress.cloud:\nEmail Direct Mail Customized online advertising   You can unsubscribe at any time by clicking the link in the footer of our emails. For information about our privacy practices, please visit our website.\n We use Mailchimp as our marketing platform. By clicking below to subscribe, you acknowledge that your information will be transferred to Mailchimp for processing. Learn more about Mailchimp's privacy practices here.\n       \n     (function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';fnames[3]='MMERGE3';ftypes[3]='phone';}(jQuery));var $mcj = jQuery.noConflict(true); No, I just want to download the PDF \u0026ldquo;Top 7 Kubernetes Security Misconceptions and Myths Download\u0026rdquo; now.\n","date":"01","image":null,"permalink":"/download/top-7-kubernetes-security-misconceptions-and-myths-landingpage/","tags":null,"title":"Top 7 Kubernetes Security Misconceptions and Myths Download"},{"categories":null,"contents":"Download the PDF \u0026ldquo;Top 7 Kubernetes Security Misconceptions and Myths Download\u0026rdquo; now. Included a free Checklist to secure your Kubernetes!\nFree Download \n","date":"01","image":null,"permalink":"/download/top-7-kubernetes-security-misconceptions-and-myths/","tags":null,"title":"Top 7 Kubernetes Security Misconceptions and Myths Download"},{"categories":null,"contents":" Use a newer browser to see this video.   The probability of bounce increases 32% as page load time goes from 1 second to 3 seconds Google/SOASTA Research, 2017.\n\rAre your websites and apps giving you a headache? Crashing constantly, being slow? And now it crashed again, rendering your past hours of work useless?\nOur Websites are fast, stable and realiable\n  Free 15-min consultation   Content  What makes our Websites different? Our Portfolio Pricing  Portfolio per category\n Portfolio Websites CV / Personal Websites Company / Agency Websites Shops Events  What makes our Websites different? Briefly said, our websites will be programmed using static-only technologies, which will make them:\n Up to 1000x faster than other Websites (e.g. WordPress) Unhackable - if there is no server side management nothing can be hacked Really cheap to run  Head over to EasyHost to read about this in more detail.\nOur Portfolio No matter if you plan on creating a shop, a normal company website, or a dynamic CMS-driven blog or website - we\u0026rsquo;ve got you covered!\n   Website name Type Example URL     EasyCloudHost.de Company site, Blog, Shop  https://easycloudhost.de/   DataFortress.cloud Company site, Blog  https://datafortress.cloud/   BildBlatt.de WordPress Shop turned static  https://bildblatt.de/   GoodThings4U Complete Static Shop  https://goodthings4u.com/     All the posibilities\u0026hellip; If you want to create a website with us, you can choose one of the following templates, or have one created just for you.\nRemember to not buy the theme over there - this will just be the pure template, and not the setup, hosting and everything. Only use our \u0026ldquo;buy\u0026rdquo; link below.\n\rPortfolio Websites    Website name Type Example Demo     Kross Portfolio (Creative)  Demo   Northend Lab Portfolio (Webdesign)  Demo     CV / Personal website    Website name Type Example Demo     Bilberry CV  Demo   GoFolium Portfolio/CV (Tech)  Demo     Company / Agency Website Remember to not buy the theme over there - this will just be the pure template, and not the setup, hosting and everything. Only use our \u0026ldquo;buy\u0026rdquo; link below.\n\r   Website name Type Example Demo     Biztrox Company  Demo   Agen Agency (Creative)  Demo   Bexer Company  Demo     Shop Remember to not buy the theme over there - this will just be the pure template, and not the setup, hosting and everything. Only use our \u0026ldquo;buy\u0026rdquo; link below.\n\r   Website name Type Example Demo     Single product Single Product  Demo   Hargo Few Products  Demo   Detox SAAS  Demo   Agico SAAS  Demo   Adrian Multi-Shop  Demo     Events Remember to not buy the theme over there - this will just be the pure template, and not the setup, hosting and everything. Only use our \u0026ldquo;buy\u0026rdquo; link below.\n\r   Website name Type Example Demo     X-con Event  Demo     Pricing Normal Website (non-shop)  CV website Agency website Company website     Feature Website S Website M Website L Custom     6 months EasyHost Hosting ✅ ✅ ✅ ✅   Lightning fast speed w. EasyHost ✅ ✅ ✅ ✅   SSL/HTTPS (letsencrypt) ✅ ✅ ✅ ✅   Custom Domain possible ✅ ✅ ✅ ✅   1 TB traffic / m ✅ ✅ ✅ ✅   CMS [1] ❌ ✅ ✅ ✅   Custom Domain included [3] ❌ ❌ ✅ ✅   Uptime guarantee no 85% 95% 99.9%   Support extra extra 2h/month ✅   Content Writing (words) 1.000 10.000 30.000 unlimited   SEO ❌ ❌ ✅ ✅   Google/FB/Ad-Setup ❌ ❌ ✅ ✅   One-time Price 249,-€ 1.299,-€ 4.999,-€ Contact us    Prices are automatically converted to your local currency on checkout\n [1] A CMS allows you to edit the content yourself in an easy web-interface (content-management-system)\n\r[3] Migrate your existing domain or buy one from us starting at 19.99€/year. Contact us\n\r  Free 15-min consultation    Shop Website    Feature Shop S Shop M Shop L Custom     6 months EasyHost Hosting ✅ ✅ ✅ ✅   Lightning fast speed w. EasyHost ✅ ✅ ✅ ✅   SSL/HTTPS (letsencrypt) ✅ ✅ ✅ ✅   Custom Domain possible ✅ ✅ ✅ ✅   Payments (Stripe) integration ✅ ✅ ✅ ✅   1 TB traffic / m ✅ ✅ ✅ ✅   CMS [1] ❌ ✅ ✅ ✅   Custom Domain included [3] ❌ ❌ ✅ ✅   Uptime guarantee no 85% 95% 99.9%   Support extra extra 2h/month ✅   Content Writing (words) 1.000 10.000 30.000 unlimited   SEO ❌ ❌ ✅ ✅   Google/FB/Ad-Setup ❌ ❌ ✅ ✅   One-time Price 499,-€ 2.999,-€ 9.999,-€ Contact us   + Monthly Price 19.99€ 49.99€ 99.99€     Prices are automatically converted to your local currency on checkout\n [1] A CMS allows you to edit the content yourself in an easy web-interface (content-management-system)\n\r[3] Migrate your existing domain or buy one from us starting at 19.99€/year. Contact us\n\r  Free 15-min consultation   ","date":"01","image":null,"permalink":"/services/websites/","tags":null,"title":"Websites"}]